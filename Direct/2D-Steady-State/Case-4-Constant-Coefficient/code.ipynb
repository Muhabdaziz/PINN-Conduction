{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLomUAvByF54"
   },
   "source": [
    "# **Preparation**\n",
    "\n",
    "``note: Make sure your laptop/PC support TeX``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7ReT07SyIqg"
   },
   "source": [
    "## **Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71918,
     "status": "ok",
     "timestamp": 1650161437103,
     "user": {
      "displayName": "muhamad kuroyuki",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "LJbmWzPJyMUZ",
    "outputId": "8b15787c-d807-4135-f9d8-2eb9ddf2fb5e"
   },
   "outputs": [],
   "source": [
    "# Install\n",
    "!pip install PyDOE\n",
    "!pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jTowqixnhvL"
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import timeit\n",
    "import math as m\n",
    "import scipy.interpolate\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from pyDOE import lhs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgZ9q0wcyOYd"
   },
   "outputs": [],
   "source": [
    "#! sudo apt-get install texlive-latex-recommended \n",
    "#! sudo apt install texlive-latex-extra\n",
    "#! sudo apt install dvipng\n",
    "#! sudo apt install cm-super\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-59d6G_T3U7M"
   },
   "source": [
    "## **Class & Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jxmBZup8di5"
   },
   "source": [
    "### **PINN Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3979,
     "status": "ok",
     "timestamp": 1650164289205,
     "user": {
      "displayName": "muhamad kuroyuki",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "ETX5B15cY8aN"
   },
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "class Pinn:\n",
    "\n",
    "    def __init__(self, data, params, exist_model=False, file_dir=\"\"):\n",
    "        self.unpack(data, params)\n",
    "        self.initialize_variables()\n",
    "\n",
    "        # Initialize Neural Network Computational Graph\n",
    "        # Weight & biases\n",
    "        if exist_model:\n",
    "            print(\"Loading NN parameters ...\")\n",
    "            self.weights, self.biases = self.load_model(file_dir)\n",
    "        else:\n",
    "            self.weights, self.biases = self.initialize_network()\n",
    "        \n",
    "        # Placeholder & Graph\n",
    "        # Placeholder (where we put input)\n",
    "        self.initialize_placeholders()\n",
    "\n",
    "        # Computational graph of Physics-Informed\n",
    "        self.graph_network()\n",
    "\n",
    "        # Computational graph of loss\n",
    "        self.graph_loss()\n",
    "        \n",
    "        # Optimizers\n",
    "        self.initialize_optimizers()\n",
    "\n",
    "        # Session\n",
    "        self.initialize_session()\n",
    "\n",
    "    def callback(self, loss_test, loss_total, loss_collo, loss_neu, loss_dir):\n",
    "        self.count += 1\n",
    "        self.loss_test_log.append(loss_test)\n",
    "        self.loss_total_log.append(loss_total)\n",
    "        self.loss_collo_log.append(loss_collo)\n",
    "        self.loss_dir_log.append(loss_dir)\n",
    "        self.loss_neu_log.append(loss_neu)\n",
    "        \n",
    "        if self.count % self.verboses_newton == 0:    \n",
    "            print(\"iter: %d, Loss_Test: %.4e, Loss Total: %.4e, Loss Collo: %.4e, Loss Neumann: %.4e, Loss Dirichlet: %.4e\" %\n",
    "                  (self.count, loss_test, loss_total, loss_collo, loss_neu, loss_dir))\n",
    "\n",
    "    def normalize_input_data(self):\n",
    "        # Normalize data\n",
    "        x_c = self.normalize_data(data=self.x_c, axis=\"x\")\n",
    "        y_c = self.normalize_data(data=self.y_c, axis=\"y\")\n",
    "        x_left = self.normalize_data(data=self.x_left, axis=\"x\")\n",
    "        y_left = self.normalize_data(data=self.y_left, axis=\"y\")\n",
    "        x_right = self.normalize_data(data=self.x_right, axis=\"x\")\n",
    "        y_right = self.normalize_data(data=self.y_right, axis=\"y\")\n",
    "        x_lower = self.normalize_data(data=self.x_lower, axis=\"x\")\n",
    "        y_lower = self.normalize_data(data=self.y_lower, axis=\"y\")\n",
    "        x_upper = self.normalize_data(data=self.x_upper, axis=\"x\")\n",
    "        y_upper = self.normalize_data(data=self.y_upper, axis=\"y\")\n",
    "        x_test = self.normalize_data(data=self.x_test, axis=\"x\")\n",
    "        y_test = self.normalize_data(data=self.y_test, axis=\"y\")\n",
    "\n",
    "        return x_c, y_c, x_left, y_left, x_right, y_right, x_lower, y_lower, x_upper, y_upper, x_test, y_test\n",
    "\n",
    "    def fit_newton(self):\n",
    "        # Change flag\n",
    "        self.newton_started = True\n",
    "\n",
    "        # Normalize data\n",
    "        (x_c, y_c, \n",
    "         x_left, y_left, \n",
    "         x_right, y_right, \n",
    "         x_lower, y_lower,\n",
    "         x_upper, y_upper,\n",
    "         x_test, y_test) = self.normalize_input_data()\n",
    "\n",
    "        tf_dict = {self.x_c_tf: x_c, self.y_c_tf: y_c,                          # collocation data\n",
    "                   self.x_left_tf: x_left, self.y_left_tf: y_left,              # left data (pts)\n",
    "                   self.u_left_tf: self.u_left, \n",
    "                   self.x_right_tf: x_right, self.y_right_tf: y_right,          # right data\n",
    "                   self.u_right_tf: self.u_right,\n",
    "                   self.x_lower_tf: x_lower, self.y_lower_tf: y_lower,          # lower data\n",
    "                   self.u_lower_tf: self.u_lower,  \n",
    "                   self.x_upper_tf: x_upper, self.y_upper_tf: y_upper,          # upper data\n",
    "                   self.u_upper_tf: self.u_upper,\n",
    "                   self.x_test_tf: x_test, self.y_test_tf: y_test,              # test data\n",
    "                   self.u_test_tf: self.u_test}\n",
    "               \n",
    "        self.train_op_newton.minimize(self.sess,\n",
    "                                      feed_dict=tf_dict,\n",
    "                                      fetches=[self.loss_test, self.loss_total,\n",
    "                                              self.loss_collo, self.loss_neu, \n",
    "                                              self.loss_dir],\n",
    "                                      loss_callback=self.callback)\n",
    "\n",
    "    def grad_finder(self):\n",
    "        self.grad_x_left = tf.gradients(self.u_left_pred, self.x_left_tf)[0] / self.sigma_x\n",
    "        self.grad_x_right = tf.gradients(self.u_right_pred, self.x_right_tf)[0] / self.sigma_x\n",
    "        self.grad_y_lower = tf.gradients(self.u_lower_pred, self.y_lower_tf)[0] / self.sigma_y\n",
    "\n",
    "    def graph_loss(self):\n",
    "        # Test\n",
    "        self.loss_test = tf.math.sqrt(tf.reduce_mean(tf.square(self.u_test_tf - self.u_test_pred)))\n",
    "\n",
    "        # Collocation points\n",
    "        self.loss_collo = tf.reduce_mean(tf.square(self.f_pred_u)) \n",
    "        \n",
    "        # Boundary\n",
    "        self.grad_finder()\n",
    "        self.loss_dir = tf.reduce_mean(tf.square(self.u_upper_pred-self.u_upper_tf))\n",
    "        self.loss_neu = tf.reduce_mean(tf.square(self.grad_x_left-self.u_left_tf)) \\\n",
    "                        + tf.reduce_mean(tf.square(self.grad_x_right-self.u_right_tf)) \\\n",
    "                        + tf.reduce_mean(tf.square(self.grad_y_lower-self.u_lower_tf))\n",
    "\n",
    "        self.loss_collo = self.coef_bc_val*(self.loss_collo)\n",
    "\n",
    "        self.loss_total = self.loss_neu + self.loss_collo + self.loss_dir\n",
    "\n",
    "    def graph_network(self):\n",
    "        # Test data\n",
    "        (self.u_test_pred) = self.net_dnn(self.x_test_tf, self.y_test_tf)\n",
    "        \n",
    "        # Predict data\n",
    "        (self.u_pred) = self.net_dnn(self.x_tf, self.y_tf)\n",
    "        \n",
    "        # Collocation points\n",
    "        (self.f_pred_u) = self.net_physics(self.x_c_tf, self.y_c_tf)\n",
    "        \n",
    "        # left\n",
    "        (self.u_left_pred) = self.net_dnn(self.x_left_tf, self.y_left_tf)\n",
    "        \n",
    "        # right\n",
    "        (self.u_right_pred) = self.net_dnn(self.x_right_tf, self.y_right_tf)\n",
    "        \n",
    "        # Lower\n",
    "        (self.u_lower_pred) = self.net_dnn(self.x_lower_tf, self.y_lower_tf)\n",
    "        \n",
    "        # Upper\n",
    "        (self.u_upper_pred) = self.net_dnn(self.x_upper_tf,self.y_upper_tf)\n",
    "\n",
    "    def load_model(self, file_dir):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(self.layers)\n",
    "        \n",
    "        with open(file_dir, 'rb') as f:\n",
    "            dnn_weights, dnn_biases = pickle.load(f)\n",
    "\n",
    "            # stored model mush has the same layers\n",
    "            assert num_layers == (len(dnn_weights)+1)\n",
    "\n",
    "            for num in range(0, num_layers-1):\n",
    "                W = tf.Variable(dnn_weights[num])\n",
    "                b = tf.Variable(dnn_biases[num])\n",
    "                weights.append(W)\n",
    "                biases.append(b)\n",
    "                print('Loaded NN parameters successfully ...')\n",
    "            \n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def initialize_network(self):\n",
    "        # Initialize\n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(self.layers)\n",
    "        layers = self.layers\n",
    "\n",
    "        # Create network\n",
    "        for lyr in range(num_layers-1):\n",
    "            # initialize weights from Xavier initialization\n",
    "            np.random.seed(self.random_seed)\n",
    "            W = self.xavier_init(size=[layers[lyr], \n",
    "                                       layers[lyr+1]])\n",
    "\n",
    "            # initialize biases = 0\n",
    "            np.random.seed(self.random_seed)\n",
    "            b = tf.Variable(tf.zeros([1, layers[lyr+1]],\n",
    "                                     dtype=tf.float32),\n",
    "                            dtype=tf.float32)\n",
    "\n",
    "            # Append generated weights & biases to the list\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def initialize_optimizers(self):\n",
    "        self.train_op_newton = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "                                    self.loss_total,\n",
    "                                    var_list = self.weights + self.biases,\n",
    "                                    method = \"L-BFGS-B\",\n",
    "                                    options = {\"maxiter\": 100000,\n",
    "                                               \"maxfun\": 10000,\n",
    "                                               \"maxcor\": 50,\n",
    "                                               \"maxls\": 50,\n",
    "                                               \"ftol\": 1e8*np.finfo(float).eps}) \n",
    "        \n",
    "    def initialize_placeholders(self):\n",
    "        # Test data\n",
    "        self.x_test_tf = tf.placeholder(tf.float32, shape=[None, self.x_test.shape[1]])\n",
    "        self.y_test_tf = tf.placeholder(tf.float32, shape=[None, self.y_test.shape[1]])\n",
    "        self.u_test_tf = tf.placeholder(tf.float32, shape=[None, self.u_test.shape[1]])\n",
    "        \n",
    "        # Predict data\n",
    "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x_c.shape[1]])\n",
    "        self.y_tf = tf.placeholder(tf.float32, shape=[None, self.y_c.shape[1]])\n",
    "\n",
    "        # Collocation data\n",
    "        self.x_c_tf = tf.placeholder(tf.float32, shape=[None, self.x_c.shape[1]])\n",
    "        self.y_c_tf = tf.placeholder(tf.float32, shape=[None, self.y_c.shape[1]])\n",
    "\n",
    "        # Boundary data\n",
    "        # left\n",
    "        self.x_left_tf = tf.placeholder(tf.float32, shape=[None, self.x_left.shape[1]])\n",
    "        self.y_left_tf = tf.placeholder(tf.float32, shape=[None, self.y_left.shape[1]])\n",
    "        self.u_left_tf = tf.placeholder(tf.float32, shape=[None, self.u_left.shape[1]])\n",
    "\n",
    "        # right\n",
    "        self.x_right_tf = tf.placeholder(tf.float32, shape=[None, self.x_right.shape[1]])\n",
    "        self.y_right_tf = tf.placeholder(tf.float32, shape=[None, self.y_right.shape[1]])\n",
    "        self.u_right_tf = tf.placeholder(tf.float32, shape=[None, self.u_right.shape[1]])\n",
    "\n",
    "        # Lower\n",
    "        self.x_lower_tf = tf.placeholder(tf.float32, shape=[None, self.x_lower.shape[1]])\n",
    "        self.y_lower_tf = tf.placeholder(tf.float32, shape=[None, self.y_lower.shape[1]])\n",
    "        self.u_lower_tf = tf.placeholder(tf.float32, shape=[None, self.u_lower.shape[1]])\n",
    "\n",
    "        self.x_upper_tf = tf.placeholder(tf.float32, shape=[None, self.x_upper.shape[1]])\n",
    "        self.y_upper_tf = tf.placeholder(tf.float32, shape=[None, self.y_upper.shape[1]])\n",
    "        self.u_upper_tf = tf.placeholder(tf.float32, shape=[None, self.u_upper.shape[1]])\n",
    "\n",
    "    def initialize_session(self):\n",
    "        tf_config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                                   log_device_placement=True)\n",
    "        self.sess = tf.Session(config=tf_config)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def initialize_variables(self):\n",
    "        # For saving loss\n",
    "        self.loss_total_log = []\n",
    "        self.loss_collo_log = []\n",
    "        self.loss_dir_log = []\n",
    "        self.loss_neu_log = []\n",
    "        self.loss_test_log = []\n",
    "        self.count = 0\n",
    "        self.newton_started = False\n",
    "\n",
    "    def net_dnn(self, x, y):\n",
    "        # Find results\n",
    "        X = tf.concat([x, y], 1)\n",
    "        results = self.net_forward(X)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def net_forward(self, X):\n",
    "        num_layers = len(self.weights)+1\n",
    "        H = X\n",
    "        # print(H)\n",
    "\n",
    "        for lyr in range(num_layers-2):\n",
    "            W = self.weights[lyr]\n",
    "            b = self.biases[lyr]\n",
    "\n",
    "            Wx_plus_b = tf.add(tf.matmul(H, W), b)\n",
    "            H = tf.tanh(Wx_plus_b)\n",
    "\n",
    "        W = self.weights[-1]\n",
    "        b = self.biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "\n",
    "        return Y\n",
    "\n",
    "    def net_physics(self, x, y):\n",
    "        # Find results from DNN\n",
    "        T = self.net_dnn(x, y)\n",
    "\n",
    "        # Temperature gradient\n",
    "        T_x = tf.gradients(T, x)[0] / self.sigma_x\n",
    "        T_xx = tf.gradients(T_x, x)[0] / self.sigma_x\n",
    "        T_y = tf.gradients(T, y)[0] / self.sigma_y\n",
    "        T_yy = tf.gradients(T_y, y)[0] / self.sigma_y\n",
    "\n",
    "        x = x*self.sigma_x + self.mu_x\n",
    "        y = y*self.sigma_y + self.mu_y\n",
    "        Q = np.zeros(shape=(self.x_c.shape))\n",
    "        k = self.k\n",
    "        \n",
    "        for i in range(0, Q.shape[0]):            \n",
    "            if 0.2<=self.x_c[i]<=0.3 and 0.2<=self.y_c[i]<=0.3:\n",
    "                Q[i] = self.Q # W/m^3\n",
    "\n",
    "        f = k*(T_xx+T_yy) + Q\n",
    "        \n",
    "        return f\n",
    "    \n",
    "    def normalize_data(self, data, axis):\n",
    "        if axis == \"x\":\n",
    "            normalized_data = (data - self.mu_x) / self.sigma_x\n",
    "        elif axis == \"y\":\n",
    "            normalized_data = (data - self.mu_y) / self.sigma_y\n",
    "\n",
    "        return normalized_data\n",
    "\n",
    "    def predict(self, x_star, y_star):\n",
    "        # Prepare the input\n",
    "        x_star = (x_star - self.mu_x) / self.sigma_x\n",
    "        y_star = (y_star - self.mu_y) / self.sigma_y\n",
    "\n",
    "        # Create dictionary\n",
    "        tf_dict = {self.x_tf:x_star, self.y_tf:y_star}\n",
    "\n",
    "        # Predict\n",
    "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
    "\n",
    "        return u_star        \n",
    "\n",
    "    def save_loss(self, file_dir):\n",
    "        loss_test = np.array(self.loss_test_log)\n",
    "        loss_data = np.column_stack((self.loss_total_log, \n",
    "                                     self.loss_collo_log,\n",
    "                                     self.loss_dir_log,\n",
    "                                     self.loss_neu_log,\n",
    "                                     loss_test))\n",
    "        loss_df = pd.DataFrame(loss_data, columns=[\"total\", \"collo\", \"dirichlet\", \"neumann\", \"error_u\"])\n",
    "        joblib.dump(loss_df, file_dir)\n",
    "\n",
    "    def save_model(self, file_dir):\n",
    "        weights = self.sess.run(self.weights)\n",
    "        biases = self.sess.run(self.biases)\n",
    "        with open(file_dir, 'wb') as f:\n",
    "            pickle.dump([weights, biases], f)\n",
    "            print(\"Save NN parameters successfully...\")\n",
    "\n",
    "    def unpack(self, data, params):\n",
    "        # Initialize\n",
    "        self.data = data\n",
    "        self.params = params\n",
    "\n",
    "        # Unpack Parameters\n",
    "        # Data-Boundary\n",
    "        self.lb = params[\"data\"][\"lb\"]\n",
    "        self.ub = params[\"data\"][\"ub\"]\n",
    "\n",
    "        self.random_seed = data[\"train\"][\"random_seed\"]\n",
    "        \n",
    "        # Data-Collocation\n",
    "        self.x_c = data[\"train\"][\"collo\"][:, 0:1]\n",
    "        self.y_c = data[\"train\"][\"collo\"][:, 1:2]\n",
    "        self.mu_x = data[\"train\"][\"mu_x\"]\n",
    "        self.mu_y = data[\"train\"][\"mu_y\"]\n",
    "        self.sigma_x = data[\"train\"][\"sigma_x\"]\n",
    "        self.sigma_y = data[\"train\"][\"sigma_y\"]\n",
    "        \n",
    "        # Data-left\n",
    "        self.x_left = data[\"train\"][\"left\"][:, 0:1]\n",
    "        self.y_left = data[\"train\"][\"left\"][:, 1:2]\n",
    "        self.u_left = data[\"train\"][\"left\"][:, 2:3]\n",
    "\n",
    "        # Data-right\n",
    "        self.x_right = data[\"train\"][\"right\"][:, 0:1]\n",
    "        self.y_right = data[\"train\"][\"right\"][:, 1:2]\n",
    "        self.u_right = data[\"train\"][\"right\"][:, 2:3]\n",
    "        \n",
    "        # Data-lower\n",
    "        self.x_lower = data[\"train\"][\"lower\"][:, 0:1]\n",
    "        self.y_lower = data[\"train\"][\"lower\"][:, 1:2]\n",
    "        self.u_lower = data[\"train\"][\"lower\"][:, 2:3]\n",
    "\n",
    "        # Data-upper\n",
    "        self.x_upper = data[\"train\"][\"upper\"][:, 0:1]\n",
    "        self.y_upper = data[\"train\"][\"upper\"][:, 1:2]\n",
    "        self.u_upper = data[\"train\"][\"upper\"][:, 2:3]\n",
    "\n",
    "        # Data-Test\n",
    "        self.x_test = data[\"test\"][:, 0:1]\n",
    "        self.y_test = data[\"test\"][:, 1:2]\n",
    "        self.u_test = data[\"test\"][:, 2:3]\n",
    "        \n",
    "        # # Physic\n",
    "        self.k   = params[\"physic\"][\"k\"]\n",
    "        self.Q   = params[\"physic\"][\"Q\"]\n",
    "\n",
    "        # Network\n",
    "        self.layers = params[\"network\"][\"layers\"]\n",
    "        self.coef_bc_val = np.array(params[\"network\"][\"coef_bc\"])\n",
    "        self.verboses_newton = params[\"network\"][\"verboses_newton\"]\n",
    "        self.saver = params[\"network\"][\"saver\"]\n",
    "\n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = np.sqrt(2 / (in_dim + out_dim))\n",
    "\n",
    "        np.random.seed(self.random_seed)\n",
    "        var = tf.Variable(tf.truncated_normal([in_dim, out_dim], \n",
    "                                               stddev=xavier_stddev, \n",
    "                                               dtype=tf.float32,\n",
    "                                               seed=40), \n",
    "                           dtype=tf.float32)\n",
    "        return var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-14xgy3Q8gk7"
   },
   "source": [
    "### **Cases**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMMyf1hZerfw"
   },
   "source": [
    "#### 2D Steady"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zz7LrZbKMDR1"
   },
   "source": [
    "##### Finite Element (Ref: Zuhal et. al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtCzOuZl1IBd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "import scipy\n",
    "import warnings\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class Conduction:\n",
    "    \"\"\"\n",
    "    Solver for 2D heat conduction with heat source on the plate and\n",
    "    Gaussian random field as the conductivity coefficient.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x=(-0.5, 0.5), y=(-0.5, 0.5)):\n",
    "        \"\"\"\n",
    "        Initialize the variables\n",
    "        Args:\n",
    "            x (tuple): tuple of x coordinates (x0,x1)\n",
    "            y (tuple): tuple of x coordinates (y0,y1)\n",
    "        \"\"\"\n",
    "        self.ndimen = 2\n",
    "        self.x0 = x[0]\n",
    "        self.y0 = y[0]\n",
    "        self.x1 = x[1]\n",
    "        self.y1 = y[1]\n",
    "        self.length = self.x1 - self.x0\n",
    "        self.width = self.y1 - self.y0\n",
    "\n",
    "    def run(self,xi,nx,ny,k,view=True):\n",
    "        \"\"\"\n",
    "        Wrapper to run the code\n",
    "        Arg:\n",
    "            - xi (nparray): array of input\n",
    "        Return:\n",
    "            - tavgB (float): Average temperature inside region B\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        gridx, gridy = self.creategrid(nx, ny, view=False)\n",
    "        gx = self.calculatealpha(xi, gridx, gridy, 0.2, view=False)\n",
    "        self.creatematrix(gx)\n",
    "        self.solve(view=view)\n",
    "        tavgB = self.calcB()\n",
    "        return tavgB\n",
    "\n",
    "    def creatematrix(self, kx):\n",
    "        matsize = np.size(self.z,0)\n",
    "        self.coeffmat = np.zeros(shape=[matsize,matsize])\n",
    "\n",
    "        # Create lower neumann BC\n",
    "        for i in range(self.nx+1):\n",
    "            self.coeffmat[i,i] = 1\n",
    "            self.coeffmat[i,i+self.nx+1] = -1\n",
    "\n",
    "        # Create upper dirichlet BC\n",
    "        for i in range(-(self.nx+1),0):\n",
    "            self.coeffmat[i,i] = 1\n",
    "\n",
    "        # Create the remaining\n",
    "        for i in range(self.nx+1,matsize-(self.nx+1)):\n",
    "            if i % (self.nx+1) == 0: # left neumann BC\n",
    "                self.coeffmat[i, i] = 1\n",
    "                self.coeffmat[i, i + 1] = -1\n",
    "            elif i % (self.nx+1) == self.nx: # right neumann BC\n",
    "                self.coeffmat[i, i] = 1\n",
    "                self.coeffmat[i, i - 1] = -1\n",
    "            else:\n",
    "                iloc,jloc = self.z[i,:]\n",
    "                iloc = int((np.round(iloc,2) + 0.5)*100)\n",
    "                jloc = int((np.round(jloc,2) + 0.5)*100)\n",
    "                # k1 = (kx[jloc,iloc+1] - kx[jloc,iloc+1]) / ((2*self.dx)**2)\n",
    "                # k2 = (kx[jloc+1,iloc] - kx[jloc-1,iloc]) / ((2*self.dy)**2)\n",
    "                # k3 = kx[jloc,iloc] / (self.dx**2)\n",
    "                # k4 = kx[jloc, iloc] / (self.dy ** 2)\n",
    "                k1 = (kx - kx) / ((2*self.dx)**2)\n",
    "                k2 = (kx - kx) / ((2*self.dy)**2)\n",
    "                k3 = kx / (self.dx**2)\n",
    "                k4 = kx / (self.dy ** 2)\n",
    "                self.coeffmat[i,i] = 2*(k3+k4)\n",
    "                self.coeffmat[i, i - 1] = -(k3-k1)\n",
    "                self.coeffmat[i, i + 1] = -(k3+k1)\n",
    "                self.coeffmat[i, i - (self.nx + 1)] = -(k4-k2)\n",
    "                self.coeffmat[i, i + (self.nx + 1)] = -(k4+k2)\n",
    "\n",
    "    def solve(self, view=False):\n",
    "        self.source = np.zeros(shape=[np.size(self.z,0)])\n",
    "        for i in range(np.size(self.z,0)):\n",
    "            x = self.z[i,0]\n",
    "            y = self.z[i,1]\n",
    "            if (x >= 0.2 and x <= 0.3) and ((y >= 0.2 and y <= 0.3)):\n",
    "                self.source[i] = 2000\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        self.tdist = np.linalg.solve(self.coeffmat,self.source)\n",
    "        tdist = self.tdist.reshape((self.nx+1, self.ny+1))\n",
    "        if view:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(3, 3), dpi=300, constrained_layout=False)\n",
    "            surf = ax.imshow(tdist, cmap=cm.jet, extent=[-0.5, 0.5, -0.5, 0.5], origin='lower', interpolation='bilinear')\n",
    "            clb = fig.colorbar(surf)\n",
    "            clb.ax.set_title('T[\\u2103]')\n",
    "            plt.show()\n",
    "\n",
    "    def calcB(self):\n",
    "        blist = []\n",
    "        for i in range(np.size(self.z,0)):\n",
    "            x = self.z[i, 0]\n",
    "            y = self.z[i, 1]\n",
    "            if (x >= -0.3 and x <= -0.2) and ((y >= -0.3 and y <= -0.2)):\n",
    "                blist.append(self.tdist[i])\n",
    "            else:\n",
    "                pass\n",
    "        blist = np.array(blist)\n",
    "        TavgB = np.sum(blist*(0.01**2)) / 0.01\n",
    "        return TavgB\n",
    "\n",
    "\n",
    "    def calculatealpha(self, xi, gridx, gridy, theta=0.2, view=False):\n",
    "        grfx, grfy = self.rndfgrid()\n",
    "        M, li, phii = self.grandomfield(theta,grfx,grfy)\n",
    "        self.z = np.hstack((gridx.reshape(self.nn, 1), gridy.reshape(self.nn, 1)))\n",
    "#         gx = np.zeros(shape=[np.size(self.z,0)])\n",
    "#         for i in range(np.size(self.z,0)):\n",
    "#             gx[i] = self.calcgz(self.z[i,:],M,xi,li,phii)\n",
    "#         gx = gx.reshape((np.size(gridx,0), np.size(gridx,1)))\n",
    "\n",
    "#         if view:\n",
    "#             fig = plt.figure()\n",
    "#             ax = fig.gca(projection='3d')\n",
    "#             surf = ax.plot_surface(gridx, gridy,gx,cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "#             plt.show()\n",
    "\n",
    "        # kx = np.exp(1 + gx*0.3)\n",
    "        kx = self.k\n",
    "        return kx\n",
    "\n",
    "    def creategrid(self, nx=100, ny=100, view=False):\n",
    "        \"\"\"\n",
    "        Create discretization for finite difference heat equation solver.\n",
    "        Args:\n",
    "             - nx (int): number of spacing on X direction. Default to 100. (number of points is nx+1)\n",
    "             - ny (int): number of spacing on Y direction. Default to 100. (number of points is ny+1)\n",
    "             - view (bool): visualize grid or not. Default to False.\n",
    "         Returns:\n",
    "             - gridx (nparray): x coordinates for each point across the space.\n",
    "             - gridy (nparray): y coordinates for each point across the space.\n",
    "        \"\"\"\n",
    "        self.nx = nx\n",
    "        self.ny = ny\n",
    "        xx = np.linspace(self.x0, self.x1, nx + 1)\n",
    "        yy = np.linspace(self.y0, self.y1, ny + 1)\n",
    "        self.nn = (nx + 1) * (ny + 1)\n",
    "        gridx, gridy = np.meshgrid(xx, yy)\n",
    "        self.dx = self.length / nx\n",
    "        self.dy = self.width / ny\n",
    "\n",
    "        if view is True:\n",
    "            for i in range(nx + 1):\n",
    "                temp1 = np.array([[-0.5, yy[i]], [0.5, yy[i]]])\n",
    "                temp2 = np.array([[xx[i], -0.5], [xx[i], 0.5]])\n",
    "                plt.plot(temp1[:, 0], temp1[:, 1], 'k')\n",
    "                plt.plot(temp2[:, 0], temp2[:, 1], 'k')\n",
    "            # plt.scatter(gridx, gridy)\n",
    "            plt.show()\n",
    "\n",
    "        return gridx, gridy\n",
    "\n",
    "    def rndfgrid(self, nx=10, ny=10, view=False):\n",
    "        \"\"\"\n",
    "        Create RGF nodes in the domain.\n",
    "        Args:\n",
    "            nx (int): number of spacing on X direction. Default to 10. (number of points is nx+1)\n",
    "            ny (int): number of spacing on Y direction. Default to 10. (number of points is ny+1)\n",
    "            view (bool): display nodes or not.\n",
    "        Returns:\n",
    "             - rf_gridx (nparray): x coordinates for each point across the space.\n",
    "             - rf_gridy (nparray): y coordinates for each point across the space.\n",
    "        \"\"\"\n",
    "        rf_xx = np.linspace(self.x0, self.x1, nx+1)\n",
    "        rf_yy = np.linspace(self.y0, self.y1, ny+1)\n",
    "        self.rf_nn = (nx+1) * (ny+1)\n",
    "        rf_gridx, rf_gridy = np.meshgrid(rf_xx, rf_yy)\n",
    "\n",
    "        if view is True:\n",
    "            for i in range(nx+1):\n",
    "                temp1 = np.array([[-0.5, rf_yy[i]], [self.rf_yy[i]]])\n",
    "                temp2 = np.array([[rf_xx[i], -0.5], [rf_xx[i], 0.5]])\n",
    "                plt.plot(temp1[:, 0], temp1[:, 1], 'k')\n",
    "                plt.plot(temp2[:, 0], temp2[:, 1], 'k')\n",
    "            plt.scatter(rf_gridx, rf_gridy)\n",
    "            plt.show()\n",
    "\n",
    "        return rf_gridx,rf_gridy\n",
    "\n",
    "    def grandomfield(self, theta, rf_gridx, rf_gridy):\n",
    "        \"\"\"\n",
    "        Calculate the components inside the Gaussian random field.\n",
    "        Args:\n",
    "            - theta (float): Lengthscale of Kernel function\n",
    "            - rf_gridx (nparray):  x coordinates for each point of GRF grid across the space.\n",
    "            - rf_gridy (nparray):  y coordinates for each point of GRF grid across the space.\n",
    "        Returns:\n",
    "            - M (int): Number of dimension of the input variables.\n",
    "            - li (nparray): Eigenvalues of correlation matrix.\n",
    "            - phii (nparray): Eigenvectors of correlation matrix.\n",
    "        \"\"\"\n",
    "        self.theta = theta * np.ones(shape=[self.ndimen])\n",
    "        self.zeta = np.hstack((rf_gridx.reshape(self.rf_nn, 1), rf_gridy.reshape(self.rf_nn, 1,)))\n",
    "        c_zetazeta = kernel(self.zeta, self.zeta, self.ndimen, self.theta)\n",
    "        li, phii = np.linalg.eigh(c_zetazeta)\n",
    "        li = np.flip(li,0)\n",
    "        phii = np.flip(phii,1)\n",
    "\n",
    "        for M in range(1,self.rf_nn+1):\n",
    "            temp1 = np.sum(li[:M]) / np.sum(li)\n",
    "            if temp1 >= 0.99:\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        return M,li,phii\n",
    "\n",
    "#     def calcgz(self,z,M,xi,li,phii):\n",
    "#         c_zzeta = kernel(z, self.zeta, self.ndimen, self.theta).transpose()\n",
    "#         gztemp = np.zeros(shape=[M])\n",
    "#         for i in range(M):\n",
    "#             gztemp[i] = (xi[i]/np.sqrt(li[i])) * np.dot(phii[:,i], c_zzeta)\n",
    "#         gz = np.sum(gztemp)\n",
    "#         return gz\n",
    "\n",
    "    def basisfunc(self,z,i,phii):\n",
    "        c_zzeta = kernel(z, self.zeta, self.ndimen, self.theta).transpose()\n",
    "        gztemp = np.dot(phii[:,i], c_zzeta)\n",
    "        return gztemp\n",
    "\n",
    "def kernel(XN, XM, nvar, theta):\n",
    "    if XN.ndim == 1:\n",
    "        XN = np.array([XN])\n",
    "    mdist = np.zeros((np.size(XN, 0), np.size(XM, 0), nvar))\n",
    "    for ii in range(0, nvar):\n",
    "        X1 = np.transpose(np.array([XN[:, ii]]))\n",
    "        X2 = np.transpose(np.array([XM[:, ii]]))\n",
    "        mdist[:, :, ii] = (cdist(X1, X2, 'euclidean') ** 2) / (theta[ii] ** 2)\n",
    "    Psi = np.exp(-1 * np.sum(mdist, 2))\n",
    "    return Psi\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     case = 2\n",
    "#     if case == 1:\n",
    "#         test = Conduction()\n",
    "#         gridx, gridy = test.creategrid(100, 100, view=False)\n",
    "#         grfx, grfy = test.rndfgrid()\n",
    "#         z = np.hstack((gridx.reshape(test.nn, 1), gridy.reshape(test.nn, 1)))\n",
    "#         M, li, phii = test.grandomfield(0.2, grfx, grfy)\n",
    "#         gx = np.zeros(shape=[np.size(z, 0)])\n",
    "#         fig, axs = plt.subplots(nrows=4, ncols=5, figsize=(11, 11), subplot_kw={'xticks': [], 'yticks': []})\n",
    "#         for j in range(20):\n",
    "#             ax = axs.flat[j]\n",
    "#             for i in range(np.size(z, 0)):\n",
    "#                 gx[i] = test.basisfunc(z[i, :], j, phii)\n",
    "#             gxi = gx.reshape((np.size(gridx,0), np.size(gridx,1)))\n",
    "#             surf = ax.imshow(gxi, cmap=cm.jet, extent=[-0.5, 0.5, -0.5, 0.5], origin='lower', interpolation='bilinear')\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         xi = 1*np.random.randn(53)\n",
    "#         t = time.time()\n",
    "#         plate = Conduction()\n",
    "#         tavgB = plate.run(xi, view=True)\n",
    "#         print(tavgB)\n",
    "#         elapsed = time.time() - t\n",
    "#         print(elapsed,'s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjzK-3YLMH6T"
   },
   "source": [
    "##### PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PdzlFo9qY2OB"
   },
   "outputs": [],
   "source": [
    "class Plate:\n",
    "    def __init__(self, add_noise=False, save_fig=False):\n",
    "        self.add_noise = add_noise\n",
    "        self.save_fig = save_fig\n",
    "        self.data = {}\n",
    "\n",
    "    def generate_bc(self, loc):\n",
    "        if loc == \"left\":\n",
    "            n = self.n_left\n",
    "            x = np.ones((n,1)) * self.lb[0]\n",
    "            np.random.seed(self.random_seed)\n",
    "            y = lhs(1,n) * (self.ub[1] - self.lb[1]) + self.lb[1]\n",
    "            q = self.q_left*lhs(1,n)\n",
    "\n",
    "            bc_datas = np.concatenate((x, y, q), axis=1)\n",
    "        elif loc == \"right\":\n",
    "            n = self.n_right\n",
    "            x = np.ones((n,1)) * self.ub[0]\n",
    "            np.random.seed(self.random_seed)\n",
    "            y = lhs(1,n) * (self.ub[1] - self.lb[1]) + self.lb[1]\n",
    "            q = self.q_right*lhs(1,n)\n",
    "            \n",
    "            bc_datas = np.concatenate((x, y, q), axis=1)\n",
    "        elif loc == \"lower\":\n",
    "            n = self.n_lower\n",
    "            np.random.seed(self.random_seed)\n",
    "            x = lhs(1,n) * (self.ub[0] - self.lb[0]) + self.lb[0]\n",
    "            y = np.ones((n,1)) * self.lb[1]\n",
    "            q = self.q_lower*lhs(1,n)\n",
    "\n",
    "            bc_datas = np.concatenate((x, y, q), axis=1)\n",
    "        else:\n",
    "            n = self.n_upper\n",
    "            np.random.seed(self.random_seed)\n",
    "            x = lhs(1,n) * (self.ub[0] - self.lb[0]) + self.lb[0]\n",
    "            y = np.ones((n,1)) * (self.ub[1])\n",
    "            np.random.seed(self.random_seed)\n",
    "            T = self.T_upper*lhs(1,n)\n",
    "\n",
    "            bc_datas = np.concatenate((x, y, T), axis=1)\n",
    "        \n",
    "        return bc_datas\n",
    "\n",
    "    def generate_collo(self):\n",
    "        # unpack\n",
    "        n = self.n_collo\n",
    "        lb = self.lb\n",
    "        ub = self.ub\n",
    "\n",
    "        outer = 0.05*2\n",
    "        lb_sc = self.lb_source - outer\n",
    "        ub_sc = self.ub_source + outer\n",
    "\n",
    "        # # create points\n",
    "        np.random.seed(self.random_seed)\n",
    "        collo_pts = lb + (ub-lb)*lhs(2, n, criterion=None)\n",
    "        \n",
    "        if self.model_type == \"optimized\":\n",
    "            collo_pts_ = []\n",
    "            for i in range(0, n):\n",
    "                if (collo_pts[i, 0] <= lb_sc[0] or collo_pts[i, 0] >= ub_sc[0]) or (collo_pts[i, 1] <= lb_sc[1] or collo_pts[i, 1] >= ub_sc[1]):\n",
    "                    collo_pts_.append(collo_pts[i,:])\n",
    "\n",
    "            np.random.seed(self.random_seed)\n",
    "            inner_collo = lb_sc + (ub_sc - lb_sc)*lhs(2, self.n_inner_collo)\n",
    "            collo_pts_new = np.concatenate((np.array(collo_pts_), inner_collo), axis=0)\n",
    "        elif self.model_type == \"baseline\": \n",
    "            collo_pts_new=collo_pts\n",
    "            \n",
    "        self.mu_X, self.sigma_X = collo_pts_new.mean(0), collo_pts_new.std(0)\n",
    "        self.mu_x, self.sigma_x = self.mu_X[0], self.sigma_X[0]\n",
    "        self.mu_y, self.sigma_y = self.mu_X[1], self.sigma_X[1]\n",
    "                \n",
    "        return (collo_pts_new) \n",
    "\n",
    "    def generate_train_data(self, param):\n",
    "        \n",
    "        # Unpack parameters\n",
    "        self.unpack(param)\n",
    "\n",
    "        # Generate points\n",
    "        # Generate boundary conditions data \n",
    "        left_bc = self.generate_bc('left')\n",
    "        right_bc = self.generate_bc('right')\n",
    "        lower = self.generate_bc('lower')\n",
    "        upper = self.generate_bc('upper')\n",
    "\n",
    "        # Generate collocations points data\n",
    "        collo_ = self.generate_collo()\n",
    "\n",
    "        # Pack data\n",
    "        self.data[\"train\"] = {}\n",
    "        self.data[\"train\"][\"collo\"] = collo_\n",
    "        self.data[\"train\"][\"left\"] = left_bc\n",
    "        self.data[\"train\"][\"right\"] = right_bc\n",
    "        self.data[\"train\"][\"lower\"] = lower\n",
    "        self.data[\"train\"][\"upper\"] = upper\n",
    "\n",
    "        self.data[\"train\"][\"mu_x\"] = self.mu_x\n",
    "        self.data[\"train\"][\"sigma_x\"] = self.sigma_x\n",
    "        self.data[\"train\"][\"mu_y\"] = self.mu_y\n",
    "        self.data[\"train\"][\"sigma_y\"] = self.sigma_y\n",
    "\n",
    "        self.data[\"train\"][\"random_seed\"] = self.random_seed\n",
    "    \n",
    "    def generate_test_data(self, param):\n",
    "        plate = Conduction()\n",
    "        np.random.seed(self.random_seed)\n",
    "        xi = 1*np.random.randn(53)\n",
    "        k = self.k_\n",
    "        tavgB = plate.run(xi=xi, nx=100, ny=100, k=k, view=True)\n",
    "        X_flat = plate.z[:, 0]\n",
    "        Y_flat = plate.z[:, 1]\n",
    "        T_ = plate.tdist\n",
    "\n",
    "        self.data[\"test\"] = np.column_stack((X_flat, Y_flat, T_))\n",
    "\n",
    "    def plot(self):\n",
    "        # unpack data\n",
    "        collo_ = self.data[\"train\"][\"collo\"]\n",
    "        left_ = self.data[\"train\"][\"left\"]\n",
    "        right_ = self.data[\"train\"][\"right\"]\n",
    "        lower_ = self.data[\"train\"][\"lower\"]\n",
    "        upper_ = self.data[\"train\"][\"upper\"]\n",
    "\n",
    "        # PLOT: points distribution\n",
    "        # Properties\n",
    "        plt.rc('text', usetex=True)\n",
    "        plt.rc('font', family='serif')\n",
    "\n",
    "        # Plot\n",
    "        fig_w = 10\n",
    "        fig_h = 10\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(fig_w, fig_h), constrained_layout=True, dpi=300)\n",
    "\n",
    "        ax.plot([self.lb[0], self.ub[0]], [self.lb[1], self.lb[1]], 'k')\n",
    "        ax.plot([self.lb[0], self.ub[0]], [self.ub[1], self.ub[1]], 'k')\n",
    "        ax.plot([self.lb[0], self.lb[0]], [self.ub[1], self.lb[1]], 'k')\n",
    "        ax.plot([self.ub[0], self.ub[0]], [self.ub[1], self.lb[1]], 'k')\n",
    "\n",
    "        ax.plot([0.2, 0.3], [0.2, 0.2], 'm')\n",
    "        ax.plot([0.3, 0.3], [0.2, 0.3], 'm')\n",
    "        ax.plot([0.3, 0.2], [0.3, 0.3], 'm')\n",
    "        ax.plot([0.2, 0.2], [0.3, 0.2], 'm')\n",
    "\n",
    "        ax.scatter(collo_[:,0:1], collo_[:,1:2], marker='.', alpha=0.7, c='grey', label='collo')\n",
    "        ax.scatter(left_[:,0:1], left_[:,1:2], marker='.', alpha=1.0, c='r', label='left BC')\n",
    "        ax.scatter(right_[:,0:1], right_[:,1:2], marker='.', alpha=1.0, c='g', label='right BC')\n",
    "        ax.scatter(lower_[:,0:1], lower_[:,1:2], marker='.', alpha=1.0, c='b', label='lower BC')\n",
    "        ax.scatter(upper_[:,0:1], upper_[:,1:2], marker='.', alpha=1.0, c='yellow', label='Upper BC')\n",
    "        \n",
    "        ax.set_title(\"Points distribution\", fontsize=40)\n",
    "        #ax.set_xlabel(\"$x$ (m)\", fontsize=20)\n",
    "        #ax.set_ylabel(\"$y$ (m)\", fontsize=20)\n",
    "        ax.set_xlabel(\"$x$ (m)\", fontsize=25)\n",
    "        ax.set_ylabel(\"$y$ (m)\", fontsize=25)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        ax.legend(fontsize=20, loc=4)\n",
    "        ax.grid(linestyle=\"--\")\n",
    "        ax.set_xlim(self.lb[0], self.ub[0])\n",
    "        ax.set_ylim(self.lb[1], self.ub[1])\n",
    "\n",
    "        if self.save_fig:\n",
    "            fig.savefig(\"fig_point_distribution.eps\", format=\"eps\")\n",
    "        plt.show()\n",
    "\n",
    "        if self.save_fig:\n",
    "            fig.savefig(\"fig_references.eps\", format=\"eps\")\n",
    "        plt.show()\n",
    "\n",
    "    def unpack(self, param):\n",
    "\n",
    "        # Bound\n",
    "        self.lb = param[\"data\"][\"lb\"]\n",
    "        self.ub = param[\"data\"][\"ub\"]\n",
    "        self.lb_source = param[\"data\"][\"lb_source\"]\n",
    "        self.ub_source = param[\"data\"][\"ub_source\"]\n",
    "        \n",
    "        self.model_type = param[\"data\"][\"model_type\"]\n",
    "\n",
    "        # Discretizations\n",
    "        self.n_collo = param[\"data\"][\"n_collo\"]\n",
    "        if self.model_type == \"optimized\":\n",
    "            self.n_inner_collo = param[\"data\"][\"inner_collo\"]\n",
    "        self.n_left = param[\"data\"][\"n_left\"]\n",
    "        self.n_right = param[\"data\"][\"n_right\"]\n",
    "        self.n_lower = param[\"data\"][\"n_lower\"]\n",
    "        self.n_upper = param[\"data\"][\"n_upper\"]\n",
    "        self.n_test = param[\"data\"][\"n_test\"]\n",
    "\n",
    "        self.q_left = param[\"data\"][\"left_q\"]\n",
    "        self.q_right = param[\"data\"][\"right_q\"]\n",
    "        self.q_lower = param[\"data\"][\"lower_q\"]\n",
    "        self.T_upper = param[\"data\"][\"upper_T\"]\n",
    "        \n",
    "        self.random_seed = param[\"data\"][\"seed\"]\n",
    "        \n",
    "        self.k_ = param[\"physic\"][\"k\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpZLqlZx8isK"
   },
   "source": [
    "### **Post Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZwRPWz48kf4"
   },
   "outputs": [],
   "source": [
    "class PostProcessing:\n",
    "\n",
    "    def __init__(self, model, params, save_fig=False):\n",
    "        self.save_fig = save_fig\n",
    "        self.unpack(model, params)\n",
    "\n",
    "    def calculate_pinn(self):\n",
    "        \n",
    "        self.n_x = self.n_test\n",
    "        self.n_y = self.n_test\n",
    "        self.u_pinn = self.model.predict(self.X_flat, self.Y_flat)\n",
    "        self.x_pinn_ = self.X_flat.reshape(self.n_y, self.n_x)\n",
    "        self.y_pinn_ = self.Y_flat.reshape(self.n_y, self.n_x)\n",
    "        self.u_pinn_ = self.u_pinn.reshape(self.n_y, self.n_x)\n",
    "\n",
    "    def calculate_error_plate(self):\n",
    "        x_test = self.model.x_test\n",
    "        y_test = self.model.y_test\n",
    "        u_test = self.model.u_test\n",
    "        \n",
    "        u_pred = self.model.predict(x_test, y_test)\n",
    "\n",
    "        delta_u = np.abs(u_pred - u_test)\n",
    "        self.abs_err_u = np.sum(delta_u) / (x_test.shape[0])\n",
    "\n",
    "        rel_u = delta_u / (u_test)\n",
    "        self.rel_err_u = np.sum(rel_u) / (x_test.shape[0])\n",
    "\n",
    "        delta_squared = delta_u**2\n",
    "        self.rmse_u = np.sqrt(np.sum(delta_squared) / x_test.shape[0])\n",
    "                \n",
    "        self.mean_u_test = np.mean(u_test)\n",
    "        self.SST = np.sum((u_test - self.mean_u_test)**2)\n",
    "        self.SSE = np.sum(delta_squared)\n",
    "        self.R2 = 1 - self.SSE / self.SST\n",
    "        \n",
    "        print(f\"Absolute Error: {self.abs_err_u:5f}\")\n",
    "        print(f\"Relative Error (%): {self.rel_err_u*100:5f}\")\n",
    "        print(f\"RMSE: {self.rmse_u:5f}\")\n",
    "        print(f\"- R2: {self.R2:5f}\")\n",
    "\n",
    "    def create_test_data(self):\n",
    "        # Find fraction\n",
    "\n",
    "        self.x = np.linspace(self.lb[0], self.ub[0], num=self.n_test)\n",
    "        self.y = np.linspace(self.lb[1], self.ub[1], num=self.n_test)\n",
    "        self.X, self.Y = np.meshgrid(self.x, self.y)\n",
    "        self.X_flat = self.model.x_test\n",
    "        self.Y_flat = self.model.y_test\n",
    "\n",
    "    def display_loss(self):\n",
    "        # SET\n",
    "        plt.rc('text', usetex=True)\n",
    "        plt.rc('font', family='serif')\n",
    "\n",
    "        # Extract data\n",
    "        loss_total = np.sqrt(self.model.loss_total_log)\n",
    "        loss_collo = np.sqrt(self.model.loss_collo_log)\n",
    "        loss_test = self.model.loss_test_log\n",
    "        loss_dir = np.sqrt(self.model.loss_dir_log)\n",
    "        loss_neu = np.sqrt(self.model.loss_neu_log)\n",
    "\n",
    "        if self.model.newton_started:\n",
    "            run_status = \"newton\"\n",
    "        else:\n",
    "            run_status = \"none\"\n",
    "\n",
    "        # Prepare\n",
    "        iter_total = []\n",
    "\n",
    "        if run_status == \"newton\":\n",
    "            n_total = np.array(loss_total).shape[0]\n",
    "\n",
    "            for i in range(n_total):\n",
    "                iter_total.append(i)\n",
    "        else:\n",
    "            n_total = 0\n",
    "        \n",
    "        # PLOT History\n",
    "        if run_status != \"none\":\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 6), constrained_layout=True, dpi=300)\n",
    "            ax.plot(iter_total, loss_total, \"r\", linestyle=\"solid\", label=\"Physical Loss\")\n",
    "            ax.plot(iter_total, loss_collo, \"g\", linestyle=\"dashdot\", label=\"Collocation Loss\")\n",
    "            ax.plot(iter_total, loss_test, \"black\", linestyle=\"dashed\", label=\"Test Error\")\n",
    "            ax.plot(iter_total, loss_dir, \"b\", linestyle=\"dotted\", label=\"Dirichlet Boundary Loss\")\n",
    "            ax.plot(iter_total, loss_neu, 'purple',linestyle='solid', label='Neumann Boundary Loss')\n",
    "\n",
    "            ax.set_xlim(0, iter_total[-1])\n",
    "            ax.set_yscale(\"log\")\n",
    "            ax.set_xlabel(\"Iterations\", fontsize=25)\n",
    "            ax.set_ylabel(\"RMSE\", fontsize=25)\n",
    "            ax.grid(linestyle=\"--\")\n",
    "            ax.legend(fontsize=13)\n",
    "            ax.set_title('Loss History (Log Scale)', fontsize=35)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "\n",
    "            # save figure\n",
    "            if self.save_fig:\n",
    "                fig.savefig(\"fig_loss_history.eps\", format=\"eps\")\n",
    "            plt.show()\n",
    "        \n",
    "        print(f\"- Last Iterations: {iter_total[-1]}\")\n",
    "        \n",
    "    def display_contour(self):\n",
    "        # FIND: PINN results\n",
    "        self.create_test_data()\n",
    "        self.calculate_pinn()\n",
    "\n",
    "        # PLOT CONTOUR\n",
    "        fig_h = 5\n",
    "        fig_w = 5\n",
    "\n",
    "        # CALCULATE: error\n",
    "        self.calculate_error_plate()\n",
    "        \n",
    "        fig_w = fig_h\n",
    "\n",
    "        v_min = np.round(np.min(self.u_pinn_))\n",
    "        v_max = np.round(np.max(self.u_pinn_))\n",
    "        self.plot_countour(phi_=self.u_pinn_,fig_w=fig_w, fig_h=fig_h, vmin=v_min, vmax=v_max, title=\"PINN Solution\")\n",
    "        \n",
    "        \n",
    "        u_test = (self.model.u_test)\n",
    "        u_test = u_test.reshape(self.n_x,self.n_y)\n",
    "        phi = np.abs(self.u_pinn_ - u_test)\n",
    "        v_min = 0.\n",
    "        v_max = (np.max(phi))\n",
    "        self.plot_countour2(phi_= phi,fig_w=fig_w, fig_h=fig_h, vmin=v_min, vmax=v_max, title=\"Absolute Error\")\n",
    "\n",
    "        \n",
    "\n",
    "    def plot_countour(self,phi_,fig_w, fig_h, vmin, vmax, title):\n",
    "        # Set\n",
    "        plt.rc('text', usetex=True)\n",
    "        plt.rc('font', family='serif')\n",
    "        \n",
    "        # Create plot\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(fig_w, fig_h), dpi=300, constrained_layout=False)\n",
    "\n",
    "        # Unpack\n",
    "        cf = ax.imshow(phi_, cmap=cm.jet, extent=[-0.5, 0.5, -0.5, 0.5], origin='lower', interpolation='bilinear')\n",
    "        ax.set_xlim(self.lb[0], self.ub[0])\n",
    "        ax.set_ylim(self.lb[1], self.ub[1])\n",
    "        \n",
    "        ax.set_title(title, fontsize=25)\n",
    "        \n",
    "        ax.set_xlabel('$x$ (m)', fontsize=20)\n",
    "        ax.set_ylabel('$y$ (m)', fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "        # ax.contour(x, y, phi_, colors='k', linewidths=0.2, levels=50)\n",
    "        \n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        cb = fig.colorbar(cf, cax=cax)\n",
    "        \n",
    "        ticks = np.linspace(vmin, vmax, 3)\n",
    "        ticks = np.round(ticks, 2)\n",
    "        cb.set_ticks(ticks)\n",
    "        cb.ax.tick_params(labelsize=16)\n",
    "        cb.ax.set_title(\"$T$ [\\u2103]\", fontsize=20)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # save figure\n",
    "        if self.save_fig:\n",
    "            fig.savefig(f\"fig_{types}.eps\", format=\"eps\")\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_countour2(self,phi_,fig_w, fig_h, vmin, vmax, title):\n",
    "        # Set\n",
    "        plt.rc('text', usetex=True)\n",
    "        plt.rc('font', family='serif')\n",
    "        \n",
    "        # Create plot\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(fig_w, fig_h), dpi=300, constrained_layout=False)\n",
    "\n",
    "        # Unpack\n",
    "        cf = ax.imshow(phi_, cmap=cm.jet, extent=[-0.5, 0.5, -0.5, 0.5], origin='lower', interpolation='bilinear')\n",
    "        ax.set_xlim(self.lb[0], self.ub[0])\n",
    "        ax.set_ylim(self.lb[1], self.ub[1])\n",
    "        \n",
    "        ax.set_title(title, fontsize=25)\n",
    "        \n",
    "        ax.set_xlabel('$x$ (m)', fontsize=20)\n",
    "        ax.set_ylabel('$y$ (m)', fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "        # ax.contour(x, y, phi_, colors='k', linewidths=0.2, levels=50)\n",
    "        \n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        cb = fig.colorbar(cf, cax=cax)\n",
    "        \n",
    "        ticks = np.linspace(vmin, vmax, 3)\n",
    "        ticks = np.round(ticks, 2)\n",
    "        ticks[-1] = ticks[-1] - 0.01\n",
    "        ticks[0] = ticks[0] + 0.01\n",
    "        cb.set_ticks(ticks)\n",
    "        cb.ax.tick_params(labelsize=16)\n",
    "        cb.ax.set_title(\"$T$ [\\u2103]\", fontsize=20)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def unpack(self, model, params):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "\n",
    "        self.lb = params[\"data\"][\"lb\"]\n",
    "        self.ub = params[\"data\"][\"ub\"]\n",
    "        self.n_test = params[\"data\"][\"n_test\"]\n",
    "        self.coef_bc = params[\"network\"][\"coef_bc\"]\n",
    "        self.verboses_newton = params[\"network\"][\"verboses_newton\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaq_LJNqZCAR"
   },
   "source": [
    "# **RUN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3WZht2MZX4N"
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.device('/device:GPU:1'):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4p2TyP64ZHoZ"
   },
   "source": [
    "## **Heat Conduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcYF_vFYZCyZ"
   },
   "outputs": [],
   "source": [
    "def generate_param():\n",
    "  # ganti learning rate\n",
    "\n",
    "    params = {}\n",
    "    params[\"data\"] = {}\n",
    "    n = 176\n",
    "    params[\"data\"][\"n_left\"] = n #81\n",
    "    params[\"data\"][\"n_right\"] = n\n",
    "    params[\"data\"][\"n_lower\"] = n\n",
    "    params[\"data\"][\"n_upper\"] = n\n",
    "    params[\"data\"][\"n_test\"] = 101\n",
    "    params[\"data\"][\"lb\"] = np.array([-0.5, -0.5])\n",
    "    params[\"data\"][\"ub\"] = np.array([0.5, 0.5])\n",
    "    params[\"data\"][\"lb_source\"] = np.array([0.2, 0.2])\n",
    "    params[\"data\"][\"ub_source\"] = np.array([0.3, 0.3])\n",
    "    \n",
    "    params[\"data\"][\"left_q\"] = 0 \n",
    "    params[\"data\"][\"right_q\"] = 0 \n",
    "    params[\"data\"][\"lower_q\"] = 0\n",
    "    params[\"data\"][\"upper_T\"] = 0\n",
    "    seed = np.random.randint(1,10000)\n",
    "    params[\"data\"][\"seed\"] = seed\n",
    "    print(f\"Seed: {seed}\")\n",
    "\n",
    "    params[\"physic\"] = {}\n",
    "    params[\"physic\"][\"Q\"]   = 2000\n",
    "\n",
    "    params[\"network\"] = {}\n",
    "    params[\"network\"][\"coef_bc\"] = 0.001\n",
    "    params[\"network\"][\"verboses_adam\"] = 100\n",
    "    params[\"network\"][\"verboses_newton\"] = 100\n",
    "    params[\"network\"][\"saver\"] = 5000\n",
    "    params[\"network\"][\"batches\"] = 1000\n",
    "    params[\"network\"][\"lr_init\"] = 1e-3\n",
    "    params[\"network\"][\"epochs\"] = 1001 #10001\n",
    "    \n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beNqkcfmZJtv"
   },
   "source": [
    "#### **2D Steady Plate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUYLHAeiaRmo"
   },
   "source": [
    "##### **Generate Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5542,
     "status": "ok",
     "timestamp": 1650161450906,
     "user": {
      "displayName": "muhamad kuroyuki",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "fefxq0D_ZNst",
    "outputId": "3bbbf6b0-fbf9-4685-bbbb-552f7ded7632"
   },
   "outputs": [],
   "source": [
    "# choose model\n",
    "model_type = \"optimized\"\n",
    "# model_type = \"baseline\"\n",
    "\n",
    "params = generate_param()\n",
    "params[\"data\"][\"model_type\"] = model_type\n",
    "params[\"network\"][\"layers\"] = [2] + 5*[30] + [1]\n",
    "params[\"physic\"][\"k\"] = 3\n",
    "\n",
    "if model_type == \"optimized\":\n",
    "    params[\"network\"][\"coef_bc\"] = 0.001\n",
    "    params[\"data\"][\"n_collo\"] = 7000\n",
    "    params[\"data\"][\"inner_collo\"] = 1000\n",
    "elif model_type == \"baseline\":\n",
    "    params[\"network\"][\"coef_bc\"] = 1.0\n",
    "    params[\"data\"][\"n_collo\"] = 10000    \n",
    "\n",
    "case = Plate()\n",
    "case.generate_train_data(param=params)\n",
    "case.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUHAgrNw-6Qa"
   },
   "source": [
    "##### Generate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsAXHSzr-5e8"
   },
   "outputs": [],
   "source": [
    "case.generate_test_data(param=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJOUZyXRZgwz"
   },
   "source": [
    "##### **Run**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpViufx_AXYX"
   },
   "source": [
    "###### Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5027,
     "status": "ok",
     "timestamp": 1650164294229,
     "user": {
      "displayName": "muhamad kuroyuki",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "pdRbx7ICZiD3",
    "outputId": "bdcfa56f-7237-43ac-db4f-1922713c1eb9"
   },
   "outputs": [],
   "source": [
    "# Create Model Instance\n",
    "model = Pinn(data=case.data, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "  # # Fit using BFGS-B\n",
    "model.fit_newton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Results\n",
    "results = PostProcessing(model=model,\n",
    "                      params=params,\n",
    "                      save_fig=False)\n",
    "\n",
    "results.display_loss()\n",
    "results.display_contour()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Plate_new adaptive weight (1) backup bagus.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
