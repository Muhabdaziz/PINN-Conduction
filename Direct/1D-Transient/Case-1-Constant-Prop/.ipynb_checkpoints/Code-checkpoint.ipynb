{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLomUAvByF54"
   },
   "source": [
    "# **Preparation**\n",
    "\n",
    "``note: Make sure your laptop/PC support TeX``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7ReT07SyIqg"
   },
   "source": [
    "## **Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 80922,
     "status": "ok",
     "timestamp": 1650167812383,
     "user": {
      "displayName": "muhamad kuroyuki",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "LJbmWzPJyMUZ",
    "outputId": "488d8728-6a00-4ffa-f552-d9d9a5e94567"
   },
   "outputs": [],
   "source": [
    "# Install\n",
    "!pip install PyDOE\n",
    "!pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1995,
     "status": "ok",
     "timestamp": 1650167814366,
     "user": {
      "displayName": "muhamad kuroyuki",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "-jTowqixnhvL"
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import timeit\n",
    "import math as m\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from pyDOE import lhs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650167814367,
     "user": {
      "displayName": "muhamad kuroyuki",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "KgZ9q0wcyOYd"
   },
   "outputs": [],
   "source": [
    "#! sudo apt-get install texlive-latex-recommended \n",
    "#! sudo apt install texlive-latex-extra\n",
    "#! sudo apt install dvipng\n",
    "#! sudo apt install cm-super\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-59d6G_T3U7M"
   },
   "source": [
    "## **Class & Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jxmBZup8di5"
   },
   "source": [
    "### **PINN Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4238,
     "status": "ok",
     "timestamp": 1650167818597,
     "user": {
      "displayName": "muhamad kuroyuki",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "ETX5B15cY8aN"
   },
   "outputs": [],
   "source": [
    "class Pinn:\n",
    "\n",
    "    def __init__(self, data, params, exist_model=False, file_dir=\"\"):\n",
    "        # Initialize & Unpack Input data\n",
    "        self.unpack(data, params)\n",
    "        self.initialize_variables()\n",
    "\n",
    "        # Initialize Neural Network Computational Graph\n",
    "        # Weight & biases\n",
    "        if exist_model:\n",
    "            print(\"Loading NN parameters ...\")\n",
    "            self.weights, self.biases = self.load_model(file_dir)\n",
    "        else:\n",
    "            self.weights, self.biases = self.initialize_network()\n",
    "\n",
    "        # Placeholder & Graph\n",
    "        # Placeholder (where we put input)\n",
    "        self.initialize_placeholders()\n",
    "\n",
    "        # Computational graph of Physics-Informed\n",
    "        self.graph_network()\n",
    "\n",
    "        # Computational graph of loss\n",
    "        self.graph_loss()\n",
    "\n",
    "        # Optimizers\n",
    "        self.initialize_optimizers()\n",
    "\n",
    "        # Session\n",
    "        self.initialize_session()\n",
    "\n",
    "    def callback(self, loss_test, loss_total, loss_collo, loss_bound, loss_init):\n",
    "        self.count += 1\n",
    "        self.loss_test_log.append(loss_test)\n",
    "        self.loss_total_log.append(loss_total)\n",
    "        self.loss_collo_log.append(loss_collo)\n",
    "        self.loss_bound_log.append(loss_bound)\n",
    "        self.loss_initial_log.append(loss_init)\n",
    "\n",
    "        if self.count % self.verboses_newton == 0:    \n",
    "            print(\"iter: %d, Loss Test: %.4e, Loss Total: %.4e, Loss Collo: %.4e, Loss Boundary: %.4e, Loss Initial: %.4e\" %\n",
    "                  (self.count, loss_test, loss_total, loss_collo, loss_bound, loss_init))\n",
    "\n",
    "    def normalize_input_data(self):\n",
    "        # Normalize data\n",
    "        x_c = self.normalize_data(data=self.x_c, axis=\"x\")\n",
    "        t_c = self.normalize_data(data=self.t_c, axis=\"t\")\n",
    "        x_left = self.normalize_data(data=self.x_left, axis=\"x\")\n",
    "        t_left = self.normalize_data(data=self.t_left, axis=\"t\")\n",
    "        x_right = self.normalize_data(data=self.x_right, axis=\"x\")\n",
    "        t_right = self.normalize_data(data=self.t_right, axis=\"t\")\n",
    "        x_initial = self.normalize_data(data=self.x_initial, axis=\"x\")\n",
    "        t_initial = self.normalize_data(data=self.t_initial, axis=\"t\")\n",
    "        x_test = self.normalize_data(data=self.x_test, axis=\"x\")\n",
    "        t_test = self.normalize_data(data=self.t_test, axis=\"t\")\n",
    "\n",
    "        return x_c, t_c, x_left, t_left, x_right, t_right, x_initial, t_initial, x_test, t_test\n",
    "\n",
    "    def fit_newton(self):\n",
    "        # Change flag\n",
    "        self.newton_started = True\n",
    "        self.count += 0\n",
    "\n",
    "        # Normalize data\n",
    "        (x_c, t_c, \n",
    "         x_left, t_left, \n",
    "         x_right, t_right, \n",
    "         x_initial, t_initial, \n",
    "         x_test, t_test) = self.normalize_input_data()\n",
    "\n",
    "        # Create dictionary\n",
    "        tf_dict = {self.x_c_tf: x_c, self.t_c_tf: t_c,                          # collocation data\n",
    "                   self.x_left_tf: x_left, self.t_left_tf: t_left,              # left data (pts)\n",
    "                   self.u_left_tf: self.u_left, \n",
    "                   self.x_right_tf: x_right, self.t_right_tf: t_right,          # right data\n",
    "                   self.u_right_tf: self.u_right,\n",
    "                   self.x_initial_tf: x_initial, self.t_initial_tf: t_initial,  # initial data\n",
    "                   self.u_initial_tf: self.u_initial, \n",
    "                   self.x_test_tf: x_test, self.t_test_tf: t_test,              # test data\n",
    "                   self.u_test_tf:self.u_test}\n",
    "\n",
    "        # Optimize\n",
    "        self.train_op_newton.minimize(self.sess,\n",
    "                                      feed_dict=tf_dict,\n",
    "                                      fetches=[self.loss_test, self.loss_total, \n",
    "                                               self.loss_collo, self.loss_bound, self.loss_initial],\n",
    "                                      loss_callback=self.callback)\n",
    "            \n",
    "    def graph_loss(self):\n",
    "        # Test\n",
    "        self.loss_test = tf.math.sqrt(tf.reduce_mean(tf.square(self.u_test_tf - self.u_test_pred)))\n",
    "                                                     \n",
    "        # Collocation points\n",
    "        self.loss_collo = tf.reduce_mean(tf.square(self.f_pred_u)) \n",
    "        \n",
    "        # Boundary\n",
    "        self.loss_left = tf.reduce_mean(tf.square(self.u_left_pred-self.u_left_tf)) \n",
    "        self.loss_right = tf.reduce_mean(tf.square(self.u_right_pred-self.u_right_tf))\n",
    "        self.loss_initial = tf.reduce_mean(tf.square(self.u_initial_pred-self.u_initial_tf)) \n",
    "        \n",
    "        self.loss_bound = self.loss_left + self.loss_right \n",
    "        \n",
    "        # Total loss\n",
    "        self.loss_total = self.loss_collo + self.loss_bound + self.loss_initial\n",
    "\n",
    "    def graph_network(self):\n",
    "        # Test data\n",
    "        (self.u_test_pred) = self.net_dnn(self.x_test_tf, self.t_test_tf)\n",
    "        \n",
    "        # Predict data\n",
    "        (self.u_pred) = self.net_dnn(self.x_tf, self.t_tf)\n",
    "\n",
    "        # Physics Training\n",
    "        # Collocation points\n",
    "        (self.f_pred_u) = self.net_physics(self.x_c_tf, self.t_c_tf)\n",
    "\n",
    "        # left\n",
    "        (self.u_left_pred) = self.net_dnn(self.x_left_tf, self.t_left_tf)\n",
    "\n",
    "        # right\n",
    "        (self.u_right_pred) = self.net_dnn(self.x_right_tf, self.t_right_tf)\n",
    "\n",
    "        # initial\n",
    "        (self.u_initial_pred) = self.net_dnn(self.x_initial_tf, self.t_initial_tf)\n",
    "\n",
    "    def load_model(self, file_dir):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(self.layers)\n",
    "        \n",
    "        with open(file_dir, 'rb') as f:\n",
    "            dnn_weights, dnn_biases = pickle.load(f)\n",
    "\n",
    "            # stored model mush has the same layers\n",
    "            assert num_layers == (len(dnn_weights)+1)\n",
    "\n",
    "            for num in range(0, num_layers-1):\n",
    "                W = tf.Variable(dnn_weights[num])\n",
    "                b = tf.Variable(dnn_biases[num])\n",
    "                weights.append(W)\n",
    "                biases.append(b)\n",
    "                print('Loaded NN parameters successfully ...')\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def initialize_network(self):\n",
    "        # Initialize\n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(self.layers)\n",
    "\n",
    "        # Create network\n",
    "        for lyr in range(num_layers-1):\n",
    "            # initialize weights from Xavier initialization\n",
    "            np.random.seed(self.random_seed)\n",
    "            W = self.xavier_init(size=[self.layers[lyr], \n",
    "                                       self.layers[lyr+1]])\n",
    "\n",
    "            # initialize biases = 0\n",
    "            np.random.seed(self.random_seed)\n",
    "            b = tf.Variable(tf.zeros([1, self.layers[lyr+1]],\n",
    "                                     dtype=tf.float32),\n",
    "                            dtype=tf.float32)\n",
    "\n",
    "            # Append generated weights & biases to the list\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def initialize_optimizers(self):\n",
    "        self.train_op_newton = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "                                    self.loss_total,\n",
    "                                    var_list = self.weights+self.biases,\n",
    "                                    method = \"L-BFGS-B\",\n",
    "                                    options = {\"maxiter\": 100000,\n",
    "                                               \"maxfun\": 100000,\n",
    "                                               \"maxcor\": 50,\n",
    "                                               \"maxls\": 50,\n",
    "                                               \"ftol\": 1*np.finfo(float).eps})\n",
    "\n",
    "    def initialize_placeholders(self):\n",
    "        # Test data\n",
    "        self.x_test_tf = tf.placeholder(tf.float32, shape=[None, self.x_test.shape[1]])\n",
    "        self.t_test_tf = tf.placeholder(tf.float32, shape=[None, self.t_test.shape[1]])\n",
    "        self.u_test_tf = tf.placeholder(tf.float32, shape=[None, self.u_test.shape[1]])\n",
    "        \n",
    "        # Predict data\n",
    "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x_c.shape[1]])\n",
    "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t_c.shape[1]])\n",
    "\n",
    "        # Collocation data\n",
    "        self.x_c_tf = tf.placeholder(tf.float32, shape=[None, self.x_c.shape[1]])\n",
    "        self.t_c_tf = tf.placeholder(tf.float32, shape=[None, self.t_c.shape[1]])\n",
    "\n",
    "        # Boundary data\n",
    "        # left\n",
    "        self.x_left_tf = tf.placeholder(tf.float32, shape=[None, self.x_left.shape[1]])\n",
    "        self.t_left_tf = tf.placeholder(tf.float32, shape=[None, self.t_left.shape[1]])\n",
    "        self.u_left_tf = tf.placeholder(tf.float32, shape=[None, self.u_left.shape[1]])\n",
    "\n",
    "        # right\n",
    "        self.x_right_tf = tf.placeholder(tf.float32, shape=[None, self.x_right.shape[1]])\n",
    "        self.t_right_tf = tf.placeholder(tf.float32, shape=[None, self.t_right.shape[1]])\n",
    "        self.u_right_tf = tf.placeholder(tf.float32, shape=[None, self.u_right.shape[1]])\n",
    "\n",
    "        # initial\n",
    "        self.x_initial_tf = tf.placeholder(tf.float32, shape=[None, self.x_initial.shape[1]])\n",
    "        self.t_initial_tf = tf.placeholder(tf.float32, shape=[None, self.t_initial.shape[1]])\n",
    "        self.u_initial_tf = tf.placeholder(tf.float32, shape=[None, self.u_initial.shape[1]])\n",
    "\n",
    "    def initialize_session(self):\n",
    "        tf_config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                                   log_device_placement=True)\n",
    "        self.sess = tf.Session(config=tf_config)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def initialize_variables(self):\n",
    "        # For saving loss\n",
    "        self.loss_total_log = []\n",
    "        self.loss_collo_log = []\n",
    "        self.loss_bound_log = []\n",
    "        self.loss_initial_log = []\n",
    "        self.loss_test_log = []\n",
    "        self.count = 0\n",
    "        self.newton_started = False\n",
    "\n",
    "    def net_dnn(self, x, t):\n",
    "        # Find results\n",
    "        X = tf.concat([x, t], 1)\n",
    "        results = self.net_forward(X)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def net_forward(self, X):\n",
    "        num_layers = len(self.weights)+1\n",
    "        H = X\n",
    "        # print(H)\n",
    "\n",
    "        for lyr in range(num_layers-2):\n",
    "            W = self.weights[lyr]\n",
    "            b = self.biases[lyr]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "\n",
    "        W = self.weights[-1]\n",
    "        b = self.biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "\n",
    "        return Y\n",
    "\n",
    "    def net_physics(self, x, t):\n",
    "        # Find results from DNN\n",
    "        T = self.net_dnn(x, t)\n",
    "\n",
    "\n",
    "        # Temperature gradient\n",
    "        T_x = tf.gradients(T, x)[0] / self.sigma_x\n",
    "        T_xx = tf.gradients(T_x, x)[0] / self.sigma_x\n",
    "        T_t = tf.gradients(T, t)[0]  / self.sigma_t\n",
    "\n",
    "        # Physics error\n",
    "        x_ = x*self.sigma_x + self.mu_x\n",
    "        t_ = t*self.sigma_t + self.mu_t\n",
    "        f = T_t - T_xx - tf.exp(x_ + 2*t_)\n",
    "\n",
    "        return f\n",
    "    def normalize_data(self, data, axis):\n",
    "        if axis == \"x\":\n",
    "            normalized_data = (data - self.mu_x) / self.sigma_x\n",
    "        elif axis == \"t\":\n",
    "            normalized_data = (data - self.mu_t) / self.sigma_t\n",
    "\n",
    "        return normalized_data\n",
    "\n",
    "    def predict(self, x_star, t_star):\n",
    "        # Prepare the input\n",
    "        x_star = (x_star - self.mu_x) / self.sigma_x\n",
    "        t_star = (t_star - self.mu_t) / self.sigma_t\n",
    "\n",
    "        # Create dictionary\n",
    "        tf_dict = {self.x_tf:x_star, self.t_tf:t_star}\n",
    "\n",
    "        # Predict\n",
    "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
    "\n",
    "        return u_star\n",
    "\n",
    "    def save_loss(self, file_dir):\n",
    "        loss_test = np.array(self.loss_test_log)\n",
    "        loss_data = np.column_stack((self.loss_total_log, \n",
    "                                     self.loss_collo_log,\n",
    "                                     self.loss_bound_log,\n",
    "                                     loss_test))\n",
    "        loss_df = pd.DataFrame(loss_data, columns=[\"total\", \"collo\", \"boundary\", \"error_u\"])\n",
    "        joblib.dump(loss_df, file_dir)\n",
    "\n",
    "    def save_model(self, file_dir):\n",
    "        weights = self.sess.run(self.weights)\n",
    "        biases = self.sess.run(self.biases)\n",
    "\n",
    "        with open(file_dir, 'wb') as f:\n",
    "            pickle.dump([weights, biases], f)\n",
    "            print(\"Save NN parameters successfully...\")\n",
    "\n",
    "    def unpack(self, data, params):\n",
    "        # Initialize\n",
    "        self.data = data\n",
    "        self.params = params\n",
    "\n",
    "        # Unpack Parameters\n",
    "        # Data-Boundary\n",
    "        self.lb = params[\"data\"][\"lb\"]\n",
    "        self.ub = params[\"data\"][\"ub\"]\n",
    "        \n",
    "        self.random_seed = data[\"train\"][\"random_seed\"]\n",
    "        \n",
    "        # Data-Collocation\n",
    "        self.x_c = data[\"train\"][\"collo\"][:, 0:1]\n",
    "        self.t_c = data[\"train\"][\"collo\"][:, 1:2]\n",
    "        self.mu_x = data[\"train\"][\"mu_x\"]\n",
    "        self.mu_t = data[\"train\"][\"mu_t\"]\n",
    "        self.sigma_x = data[\"train\"][\"sigma_x\"]\n",
    "        self.sigma_t = data[\"train\"][\"sigma_t\"]\n",
    "        \n",
    "        # Data-left\n",
    "        self.x_left = data[\"train\"][\"left\"][:, 0:1]\n",
    "        self.t_left = data[\"train\"][\"left\"][:, 1:2]\n",
    "        self.u_left = data[\"train\"][\"left\"][:, 2:3]\n",
    "\n",
    "        # Data-right\n",
    "        self.x_right = data[\"train\"][\"right\"][:, 0:1]\n",
    "        self.t_right = data[\"train\"][\"right\"][:, 1:2]\n",
    "        self.u_right = data[\"train\"][\"right\"][:, 2:3]\n",
    "        \n",
    "        # Data-initial\n",
    "        self.x_initial = data[\"train\"][\"initial\"][:, 0:1]\n",
    "        self.t_initial = data[\"train\"][\"initial\"][:, 1:2]\n",
    "        self.u_initial = data[\"train\"][\"initial\"][:, 2:3]\n",
    "\n",
    "        # Data-Test\n",
    "        self.x_test = data[\"test\"][:, 0:1]\n",
    "        self.t_test = data[\"test\"][:, 1:2]\n",
    "        self.u_test = data[\"test\"][:, 2:3]\n",
    "\n",
    "        # Network\n",
    "        self.layers = params[\"network\"][\"layers\"]\n",
    "        self.verboses_newton = params[\"network\"][\"verboses_newton\"]\n",
    "        self.saver = params[\"network\"][\"saver\"]\n",
    "\n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = np.sqrt(2 / (in_dim + out_dim))\n",
    "\n",
    "        np.random.seed(self.random_seed)\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], \n",
    "                                               stddev=xavier_stddev, \n",
    "                                               dtype=tf.float32,\n",
    "                                               seed=self.random_seed), \n",
    "                           dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-14xgy3Q8gk7"
   },
   "source": [
    "### **Cases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1650167819356,
     "user": {
      "displayName": "muhamad kuroyuki",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "SBoYWjnT8iQt"
   },
   "outputs": [],
   "source": [
    "class Conduction:\n",
    "\n",
    "    def __init__(self, add_noise=False, save_fig=False):\n",
    "        self.add_noise = add_noise\n",
    "        self.save_fig = save_fig\n",
    "        self.data = {}\n",
    "\n",
    "    def analytics_solution(self, x, t):\n",
    "        u_ = np.exp(x+2*t)\n",
    "\n",
    "        return u_\n",
    "\n",
    "    def generate_bc(self, loc):\n",
    "        lb = self.lb\n",
    "        ub = self.ub\n",
    "        if loc == \"left\":\n",
    "            n = self.n_left\n",
    "            x = lb[0]*np.ones((n,1))\n",
    "            np.random.seed(self.random_seed)\n",
    "            t = lb[1] + (ub[1] - lb[1])*lhs(1,n)\n",
    "            T = np.exp(2*t)\n",
    "            bc_datas = np.concatenate((x, t, T), axis=1)\n",
    "            \n",
    "        elif loc == \"right\":\n",
    "            n = self.n_right\n",
    "            x = self.ub[0]*np.ones((n,1))\n",
    "            np.random.seed(self.random_seed)\n",
    "            t = lb[1] + (ub[1] - lb[1])*lhs(1,n)\n",
    "            T = np.exp(1+2*t)\n",
    "            bc_datas = np.concatenate((x, t, T), axis=1)\n",
    "        else:\n",
    "            n = self.n_initial\n",
    "            np.random.seed(self.random_seed)\n",
    "            x = lb[0] + (ub[0] - lb[0])*lhs(1,n)\n",
    "            t = lb[1]*lhs(1,n)\n",
    "            T = np.exp(x)\n",
    "            bc_datas = np.concatenate((x, t, T), axis=1)\n",
    "        \n",
    "        return bc_datas\n",
    "\n",
    "    def generate_collo(self):\n",
    "        # unpack\n",
    "        n = self.n_collo\n",
    "        lb = self.lb\n",
    "        ub = self.ub\n",
    "\n",
    "        # create points\n",
    "        np.random.seed(self.random_seed)\n",
    "        collo_pts = lb + (ub-lb)*lhs(2, n)\n",
    "\n",
    "        self.mu_X, self.sigma_X = collo_pts.mean(0), collo_pts.std(0)\n",
    "        self.mu_x, self.sigma_x = self.mu_X[0], self.sigma_X[0]\n",
    "        self.mu_t, self.sigma_t = self.mu_X[1], self.sigma_X[1]\n",
    "                \n",
    "        return collo_pts \n",
    "\n",
    "    def generate_train_data(self, param):\n",
    "        # Unpack parameters\n",
    "        self.unpack(param)\n",
    "\n",
    "        # Generate points\n",
    "        # Generate boundary conditions data \n",
    "        left_ = self.generate_bc('left')\n",
    "        right_ = self.generate_bc('right')\n",
    "        initial_ = self.generate_bc('initial')\n",
    "\n",
    "        # Generate collocations points data\n",
    "        collo_ = self.generate_collo()\n",
    "\n",
    "        # Pack data\n",
    "        self.data[\"train\"] = {}\n",
    "        self.data[\"train\"][\"collo\"] = collo_\n",
    "        self.data[\"train\"][\"left\"] = left_\n",
    "        self.data[\"train\"][\"right\"] = right_\n",
    "        self.data[\"train\"][\"initial\"] = initial_\n",
    "        self.data[\"train\"][\"mu_x\"] = self.mu_x\n",
    "        self.data[\"train\"][\"sigma_x\"] = self.sigma_x\n",
    "        self.data[\"train\"][\"mu_t\"] = self.mu_t\n",
    "        self.data[\"train\"][\"sigma_t\"] = self.sigma_t\n",
    "        self.data[\"train\"][\"random_seed\"] = self.random_seed\n",
    "\n",
    "    def generate_test_data(self, param):\n",
    "        # Unpack parameters\n",
    "        self.unpack(param)\n",
    "\n",
    "        # Generate points\n",
    "        x_ = np.linspace(self.lb[0], self.ub[0], num=self.n_test)\n",
    "        t_ = np.linspace(self.lb[1], self.ub[1], num=self.n_test)\n",
    "        X, T = np.meshgrid(x_, t_)\n",
    "        X_flat = X.flatten()[:,None]\n",
    "        T_flat = T.flatten()[:,None]\n",
    "        u_ = self.analytics_solution(X_flat, T_flat)\n",
    "\n",
    "        self.data[\"test\"] = np.column_stack((X_flat, T_flat, u_))\n",
    "\n",
    "    def plot(self):\n",
    "        # unpack data\n",
    "        collo_ = self.data[\"train\"][\"collo\"]\n",
    "        left_ = self.data[\"train\"][\"left\"]\n",
    "        right_ = self.data[\"train\"][\"right\"]\n",
    "        initial_ = self.data[\"train\"][\"initial\"]\n",
    "\n",
    "        plt.rc('text', usetex=True)\n",
    "        plt.rc('font', family='serif')\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 5), constrained_layout=True, dpi=300)\n",
    "\n",
    "        ax.plot([self.lb[0], self.ub[0]], [self.lb[1], self.lb[1]], 'k')\n",
    "        ax.plot([self.lb[0], self.ub[0]], [self.ub[1], self.ub[1]], 'k')\n",
    "        ax.plot([self.lb[0], self.lb[0]], [self.ub[1], self.lb[1]], 'k')\n",
    "        ax.plot([self.ub[0], self.ub[0]], [self.ub[1], self.lb[1]], 'k')\n",
    "\n",
    "        ax.scatter(collo_[:,0:1], collo_[:,1:2], marker='.', alpha=0.7, c='grey', label='Collo') #r'$\\mathrm{collo}$')\n",
    "        ax.scatter(left_[:,0:1], left_[:,1:2], marker='.', alpha=0.7, c='r', label='Left BC')\n",
    "        ax.scatter(right_[:,0:1], right_[:,1:2], marker='.', alpha=0.7, c='g', label='Right BC')\n",
    "        ax.scatter(initial_[:,0:1], initial_[:,1:2], marker='.', alpha=0.7, c='b', label='IC')\n",
    "\n",
    "        ax.set_title(\"Points distribution\", fontsize=18)\n",
    "        ax.set_xlabel(\"$x$ (m)\", fontsize=20)\n",
    "        ax.set_ylabel(\"$t$ (s)\", fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "        ax.legend(fontsize=10, loc=4)\n",
    "        ax.grid(linestyle=\"--\")\n",
    "        ax.set_xlim(self.lb[0], self.ub[0])\n",
    "        ax.set_ylim(self.lb[1], self.ub[1])\n",
    "\n",
    "        if self.save_fig:\n",
    "            fig.savefig(\"fig_point_distribution.eps\", format=\"eps\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        if self.save_fig:\n",
    "            fig.savefig(\"fig_references.eps\", format=\"eps\")\n",
    "        plt.show()\n",
    "\n",
    "    def unpack(self, param):\n",
    "        # # Constant\n",
    "        # Bound\n",
    "        self.lb = param[\"data\"][\"lb\"]\n",
    "        self.ub = param[\"data\"][\"ub\"]\n",
    "\n",
    "        # Discretizations\n",
    "        self.n_collo = param[\"data\"][\"n_collo\"]\n",
    "        self.n_left = param[\"data\"][\"n_left\"]\n",
    "        self.n_right = param[\"data\"][\"n_right\"]\n",
    "        self.n_initial = param[\"data\"][\"n_initial\"]\n",
    "        self.n_test = param[\"data\"][\"n_test\"]\n",
    "        self.random_seed = param[\"data\"][\"seed\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpZLqlZx8isK"
   },
   "source": [
    "### **Post Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1327,
     "status": "ok",
     "timestamp": 1650167820677,
     "user": {
      "displayName": "muhamad kuroyuki",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "nZwRPWz48kf4"
   },
   "outputs": [],
   "source": [
    "class PostProcessing:\n",
    "\n",
    "    def __init__(self, model, params, save_fig=False):\n",
    "        self.save_fig = save_fig\n",
    "        self.unpack(model, params)\n",
    "\n",
    "    def calculate_pinn(self):\n",
    "        self.u_pinn = self.model.predict(self.X_flat, self.T_flat)\n",
    "        self.x_pinn_ = self.X_flat.reshape(self.n_t, self.n_x)\n",
    "        self.t_pinn_ = self.T_flat.reshape(self.n_t, self.n_x)\n",
    "        self.u_pinn_ = self.u_pinn.reshape(self.n_t, self.n_x)\n",
    "\n",
    "    def calculate_error(self, n_data):\n",
    "        x_test = self.model.x_test \n",
    "        t_test = self.model.t_test\n",
    "\n",
    "        # Predict\n",
    "        u_pinn = self.model.predict(x_test, t_test)\n",
    "        u_test = self.model.u_test\n",
    "        u_analytic = self.model.u_test\n",
    "        delta_u = np.abs(self.u_pinn - u_analytic)\n",
    "        self.abs_err_u = np.sum(delta_u)/(self.n_x * self.n_t)\n",
    "        rel_err_u_ij = delta_u/u_analytic \n",
    "        self.rel_err_u = np.sum(rel_err_u_ij)/(self.n_x * self.n_t)\n",
    "        \n",
    "        delta_squared = delta_u**2\n",
    "        self.rmse_u = np.sqrt(np.sum(delta_squared) / (self.n_x * self.n_t))\n",
    "        \n",
    "        self.mean_u_test = np.mean(u_test)\n",
    "        self.SST = np.sum((u_test - self.mean_u_test)**2)\n",
    "        self.SSE = np.sum(delta_squared)\n",
    "        self.R2 = 1 - self.SSE / self.SST\n",
    "        \n",
    "        print(f\"- Absolute Error: {self.abs_err_u:5f}\")\n",
    "        print(f\"- Relative Error (%): {self.rel_err_u*100:5f}\")\n",
    "        print(f\"- RMSE: {self.rmse_u:5f}\")\n",
    "        print(f\"- R2: {self.R2:5f}\")\n",
    "        \n",
    "\n",
    "        return x_test, t_test, u_pinn, u_test\n",
    "\n",
    "    def create_test_data(self):\n",
    "        # Find fraction\n",
    "        length_ = self.ub - self.lb\n",
    "        min_length_ = np.argmin(length_)\n",
    "        frac_ = max(length_) / min(length_)\n",
    "        n_test_1 = int(frac_ * self.n_test)\n",
    "\n",
    "        # Create grid\n",
    "        if min_length_ == 0:\n",
    "            self.n_x = self.n_test\n",
    "            self.n_t = n_test_1\n",
    "        else:\n",
    "            self.n_x = n_test_1\n",
    "            self.n_t = self.n_test\n",
    "\n",
    "        self.x = np.linspace(self.lb[0], self.ub[0], num=self.n_x)\n",
    "        self.t = np.linspace(self.lb[1], self.ub[1], num=self.n_t)\n",
    "        self.X, self.T = np.meshgrid(self.x, self.t)\n",
    "        self.X_flat = self.X.flatten()[:, None]\n",
    "        self.T_flat = self.T.flatten()[:, None]\n",
    "\n",
    "    def display_loss(self):\n",
    "        # SET\n",
    "        plt.rc('text', usetex=True)\n",
    "        plt.rc('font', family='serif')\n",
    "\n",
    "        # Extract data\n",
    "        loss_total = np.sqrt(self.model.loss_total_log)\n",
    "        loss_collo = np.sqrt(self.model.loss_collo_log)\n",
    "        loss_initial = np.sqrt(self.model.loss_initial_log)\n",
    "        loss_bound = np.sqrt(self.model.loss_bound_log)\n",
    "        loss_test = self.model.loss_test_log\n",
    "\n",
    "        # Status\n",
    "        if self.model.newton_started:\n",
    "            run_status = \"newton\"\n",
    "        else:\n",
    "            run_status = \"none\"\n",
    "\n",
    "        # Prepare\n",
    "        iter_total = []\n",
    "\n",
    "        if run_status == \"newton\":\n",
    "            n_total = len(loss_total)\n",
    "\n",
    "            for i in range(n_total):\n",
    "                iter_total.append(i)\n",
    "        else:\n",
    "            n_total = 0\n",
    "        \n",
    "        # PLOT History\n",
    "        if run_status != \"none\":\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 6), constrained_layout=True, dpi=300)\n",
    "            ax.plot(iter_total, loss_total, \"r\", linestyle=\"solid\", label=\"Physical Loss\")\n",
    "            ax.plot(iter_total, loss_collo, \"g\", linestyle=\"dashdot\", label=\"Collocation Loss\")\n",
    "            ax.plot(iter_total, loss_bound, \"b\", linestyle=\"dotted\", label=\"Boundary Loss\")\n",
    "            ax.plot(iter_total, loss_initial, \"purple\", linestyle=\"solid\", label=\"Initial Loss\")\n",
    "            ax.plot(iter_total, loss_test, \"black\", linestyle=\"dashed\", label=\"Test Error\")\n",
    "\n",
    "            ax.set_xlim(0, iter_total[-1])\n",
    "            ax.set_yscale(\"log\")\n",
    "            ax.set_xlabel(\"Iterations\", fontsize=25)\n",
    "            ax.set_ylabel(\"RMSE\", fontsize=25)\n",
    "            ax.grid(linestyle=\"--\")\n",
    "            ax.legend(fontsize=13)\n",
    "            ax.set_title('Loss History (Log Scale)', fontsize=35)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "\n",
    "            # save figure\n",
    "            if self.save_fig:\n",
    "                fig.savefig(\"fig_loss_history.eps\", format=\"eps\")\n",
    "            plt.show()\n",
    "        \n",
    "        print(f\"- Last Iterations: {iter_total[-1]}\")\n",
    "        \n",
    "    def display_contour(self):\n",
    "        # FIND: PINN results\n",
    "        self.create_test_data()\n",
    "        self.calculate_pinn()\n",
    "        # CALCULATE: error\n",
    "        x_, t_, u_pinn, u_test = self.calculate_error(n_data = self.n_test)\n",
    "\n",
    "        # PLOT CONTOUR\n",
    "        fig_h = 3 \n",
    "        fig_w = 10\n",
    "\n",
    "        # PLOT: comparison\n",
    "        self.plot_comparison(hor_val=self.t, hor_type=\"t\",\n",
    "                             phi_pinn=u_pinn.reshape(self.n_t, self.n_x), \n",
    "                             phi_analytics=u_test.reshape(self.n_t, self.n_x), \n",
    "                             fig_w=fig_w, fig_h=fig_h*2)\n",
    "        self.plot_comparison(hor_val=self.x, hor_type=\"x\",\n",
    "                             phi_pinn=u_pinn.reshape(self.n_t, self.n_x), \n",
    "                             phi_analytics=u_test.reshape(self.n_t, self.n_x), \n",
    "                             fig_w=fig_w, fig_h=fig_h*2)\n",
    "        \n",
    "        vmin = np.min(u_pinn)\n",
    "        vmax = np.max(u_pinn)\n",
    "        self.plot_countour(x=self.X, t=self.T, \n",
    "                           x_flat=self.X_flat, t_flat=self.T_flat,\n",
    "                           phi=self.u_pinn, phi_=self.u_pinn_, \n",
    "                           vmin=vmin, vmax=vmax,\n",
    "                           types=\"T\", \n",
    "                           fig_w=fig_w, fig_h=fig_h)\n",
    "        \n",
    "    def plot_comparison(self, hor_val, hor_type, phi_pinn, phi_analytics, fig_w, fig_h):\n",
    "        #plt.rc('text', usetex=True)\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(fig_w, fig_h), dpi=100, constrained_layout=False)\n",
    "        \n",
    "        if hor_type == \"x\":\n",
    "            n = self.n_x\n",
    "            ver_type = \"t\"\n",
    "            hor_unit = \"m\"\n",
    "            ver_unit = \"s\"\n",
    "            \n",
    "            ax[0].plot(hor_val, phi_pinn[n//4,:].flatten(), 'b', label=\"PINN solution\", linewidth=4)\n",
    "            ax[0].plot(hor_val, phi_analytics[n//4,:], '--r', label=\"Analytical solution\", linewidth=4)\n",
    "            ax[1].plot(hor_val, phi_pinn[n//2,:].flatten(), 'b', label=\"PINN solution\", linewidth=4)\n",
    "            ax[1].plot(hor_val, phi_analytics[n//2,:], '--r', label=\"Analytical solution\", linewidth=4)\n",
    "            ax[2].plot(hor_val, phi_pinn[n//4*3+1,:].flatten(), 'b', label=\"PINN solution\", linewidth=4)\n",
    "            ax[2].plot(hor_val, phi_analytics[n//4*3+1,:], '--r', label=\"Analytical solution\", linewidth=4)\n",
    "            \n",
    "        elif hor_type == \"t\":\n",
    "            n = self.n_t\n",
    "            ver_type = \"x\"\n",
    "            hor_unit = \"s\"\n",
    "            ver_unit = \"m\"\n",
    "            \n",
    "            ax[0].plot(hor_val, phi_pinn[:,n//4].flatten(), 'b', label=\"PINN solution\", linewidth=4)\n",
    "            ax[0].plot(hor_val, phi_analytics[:,n//4], '--r', label=\"Analytical solution\", linewidth=4)\n",
    "            ax[1].plot(hor_val, phi_pinn[:,n//2].flatten(), 'b', label=\"PINN solution\", linewidth=4)\n",
    "            ax[1].plot(hor_val, phi_analytics[:,n//2], '--r', label=\"Analytical solution\", linewidth=4)\n",
    "            ax[2].plot(hor_val, phi_pinn[:,n//4*3+1].flatten(), 'b', label=\"PINN solution\", linewidth=4)\n",
    "            ax[2].plot(hor_val, phi_analytics[:,n//4*3+1], '--r', label=\"Analytical solution\", linewidth=4)\n",
    "        \n",
    "        x_lim_min = min(np.min(phi_pinn), np.min(phi_analytics))\n",
    "        x_lim_max = max(np.max(phi_pinn), np.max(phi_analytics))\n",
    "        x_lim_min = 0\n",
    "        x_lim_max = x_lim_max + 0.2*abs(x_lim_max)\n",
    "        \n",
    "        ax[0].set_ylim(x_lim_min, x_lim_max)\n",
    "        ax[0].set_xlim(self.lb[1], self.ub[1])\n",
    "        ax[0].set_xlabel(f\"${hor_type}$ ({hor_unit}), ${ver_type}=0.25$ {ver_unit}\", fontsize=25)\n",
    "        ax[0].set_ylabel(\"$T$ (\\u2103)\", fontsize=25)\n",
    "        ax[0].grid(linestyle=\"--\")\n",
    "        ax[0].legend(fontsize=13)\n",
    "        ax[0].tick_params(axis='both', which='major', labelsize=23)\n",
    "        \n",
    "        ax[1].set_ylim(x_lim_min, x_lim_max)\n",
    "        ax[1].set_xlim(self.lb[1], self.ub[1])\n",
    "        ax[1].set_xlabel(f\"${hor_type}$ ({hor_unit}), ${ver_type}=0.5$ {ver_unit}\", fontsize=25)\n",
    "        ax[1].set_ylabel(\"$T$ (\\u2103)\", fontsize=25)\n",
    "        ax[1].grid(linestyle=\"--\")\n",
    "        ax[1].legend(fontsize=13)\n",
    "        ax[1].set_title(\"Temperature comparison\", fontsize=45)\n",
    "        ax[1].tick_params(axis='both', which='major', labelsize=23)\n",
    "       \n",
    "        ax[2].set_ylim(x_lim_min, x_lim_max)\n",
    "        ax[2].set_xlim(self.lb[1], self.ub[1])\n",
    "        ax[2].set_xlabel(f\"${hor_type}$ ({hor_unit}), ${ver_type}=0.75$ {ver_unit}\", fontsize=25)\n",
    "        ax[2].set_ylabel(\"$T$ (\\u2103)\", fontsize=25)\n",
    "        ax[2].grid(linestyle=\"--\")\n",
    "        ax[2].legend(fontsize=13)\n",
    "        ax[2].tick_params(axis='both', which='major', labelsize=23)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        \n",
    "    def plot_countour(self, x, t, x_flat, t_flat, phi, phi_, vmin, vmax, types, fig_w, fig_h):\n",
    "        \n",
    "        # Create plot\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(fig_w, fig_h), dpi=300, constrained_layout=False)\n",
    "\n",
    "        # Unpack\n",
    "        cf = ax.scatter(x_flat, t_flat, c=phi, \n",
    "                        alpha=1., edgecolors='none', cmap='jet', marker=\".\", s=50, vmin=vmin, vmax=vmax)\n",
    "        ax.set_xlim(self.lb[0], self.ub[0])\n",
    "        ax.set_ylim(self.lb[1], self.ub[1])\n",
    "        \n",
    "        ax.set_title(f'${types}$ $(x,t)$ PINN Solution', fontsize=30)\n",
    "        \n",
    "        ax.set_xlabel('$x$ (m)', fontsize=25)\n",
    "        ax.set_ylabel('$t$ (s)', fontsize=25)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=17)\n",
    "        ax.contour(x, t, phi_, colors='k', linewidths=0.2, levels=50)\n",
    "        \n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        cb = fig.colorbar(cf, cax=cax)\n",
    "        ticks = np.linspace(vmin, vmax, 3)\n",
    "        ticks[1] = np.round(ticks[1], 2)\n",
    "        ticks[-1] = m.floor(ticks[-1]*100)/100.0\n",
    "        ticks[0] = m.ceil(ticks[0]*100)/100.0\n",
    "        cb.set_ticks(ticks)\n",
    "        cb.ax.tick_params(labelsize=17)\n",
    "\n",
    "        # Analytical Solution contour\n",
    "        u = np.exp(x_flat+2*t_flat)\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(fig_w, fig_h), dpi=300, constrained_layout=False)\n",
    "        cf = ax.scatter(x_flat, t_flat, c=u, alpha=1., edgecolors='none', cmap='jet', marker=\".\", s=50, vmin=vmin, vmax=vmax)\n",
    "        ax.set_xlim(self.lb[0], self.ub[0])\n",
    "        ax.set_ylim(self.lb[1], self.ub[1])\n",
    "        \n",
    "        ax.set_title(f'${types}$ $(x,t)$ Analytical Solution', fontsize=30)\n",
    "        \n",
    "        ax.set_xlabel('$x$ (m)', fontsize=25)\n",
    "        ax.set_ylabel('$t$ (s)', fontsize=25)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=17)\n",
    "        ax.contour(x, t, np.exp(x + 2*t), colors='k', linewidths=0.2, levels=50)\n",
    "        \n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        cb = fig.colorbar(cf, cax=cax)\n",
    "        ticks = np.linspace(vmin, vmax, 3)\n",
    "        ticks[1] = np.round(ticks[1], 2)\n",
    "        ticks[-1] = m.floor(ticks[-1]*100)/100.0\n",
    "        ticks[0] = m.ceil(ticks[0]*100)/100.0\n",
    "        cb.set_ticks(ticks)\n",
    "        cb.ax.tick_params(labelsize=17)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        # save figure\n",
    "        if self.save_fig:\n",
    "            fig.savefig(f\"fig_{types}.eps\", format=\"eps\")\n",
    "        plt.show()\n",
    "\n",
    "    def unpack(self, model, params):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "\n",
    "        self.lb = params[\"data\"][\"lb\"]\n",
    "        self.ub = params[\"data\"][\"ub\"]\n",
    "        self.n_test = params[\"data\"][\"n_test\"]\n",
    "        self.verboses_newton = params[\"network\"][\"verboses_newton\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaq_LJNqZCAR"
   },
   "source": [
    "# **RUN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3WZht2MZX4N"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set GPU to tensorflow session\n",
    "with tf.device('/device:GPU:2'):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4p2TyP64ZHoZ"
   },
   "source": [
    "## **Parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcYF_vFYZCyZ"
   },
   "outputs": [],
   "source": [
    "def generate_param():\n",
    "    params = {}\n",
    "\n",
    "    params[\"data\"] = {}\n",
    "    params[\"data\"][\"lb\"] = np.array([0., 0.])\n",
    "    params[\"data\"][\"ub\"] = np.array([1.0, 1.0])\n",
    "    params[\"data\"][\"n_collo\"] = 1000\n",
    "    params[\"data\"][\"n_left\"] = 101\n",
    "    params[\"data\"][\"n_right\"] = 101\n",
    "    params[\"data\"][\"n_initial\"] = 101\n",
    "    params[\"data\"][\"n_test\"] = 201\n",
    "    seed = np.random.randint(1,1000)\n",
    "    params[\"data\"][\"seed\"] = seed\n",
    "    print(f\"seed: {seed}\")\n",
    "\n",
    "    params[\"physic\"] = {}\n",
    "\n",
    "    params[\"network\"] = {}\n",
    "    params[\"network\"][\"verboses_newton\"] = 1000\n",
    "    params[\"network\"][\"saver\"] = 5000\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUYLHAeiaRmo"
   },
   "source": [
    "##### **Generate Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 795
    },
    "executionInfo": {
     "elapsed": 2061,
     "status": "ok",
     "timestamp": 1644941293507,
     "user": {
      "displayName": "Muhamad Abdul Aziz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHILWjr4ESArIjDWti8SP0Eoc2OKYZ3FHWCH5XZg=s64",
      "userId": "13788538733952970869"
     },
     "user_tz": -420
    },
    "id": "fefxq0D_ZNst",
    "outputId": "231be54c-e347-42d6-e281-3d8ca63ebb63"
   },
   "outputs": [],
   "source": [
    "params = generate_param()\n",
    "params[\"network\"][\"layers\"] = [2] + 1*[5] + [1]\n",
    "\n",
    "case = Conduction()\n",
    "case.generate_train_data(param=params)\n",
    "case.generate_test_data(param=params)\n",
    "case.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJOUZyXRZgwz"
   },
   "source": [
    "##### **Run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4303,
     "status": "ok",
     "timestamp": 1644941301454,
     "user": {
      "displayName": "Muhamad Abdul Aziz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHILWjr4ESArIjDWti8SP0Eoc2OKYZ3FHWCH5XZg=s64",
      "userId": "13788538733952970869"
     },
     "user_tz": -420
    },
    "id": "pdRbx7ICZiD3",
    "outputId": "b4576a58-54c8-4f5b-9a81-a0104364357b"
   },
   "outputs": [],
   "source": [
    "# Create Model Instance\n",
    "model = Pinn(data=case.data, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6576,
     "status": "ok",
     "timestamp": 1644941334270,
     "user": {
      "displayName": "Muhamad Abdul Aziz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHILWjr4ESArIjDWti8SP0Eoc2OKYZ3FHWCH5XZg=s64",
      "userId": "13788538733952970869"
     },
     "user_tz": -420
    },
    "id": "AnoNB2RDlz9C",
    "outputId": "e59b22be-be68-4f16-ef1c-487e462e5fe9"
   },
   "outputs": [],
   "source": [
    "# # Fit using BFGS-B\n",
    "model.fit_newton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Results\n",
    "results = PostProcessing(model=model,\n",
    "                      params=params,\n",
    "                      save_fig=False)\n",
    "\n",
    "results.display_loss()\n",
    "results.display_contour()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHcBtn8Pa4Tw"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_model('Dirichlet_good.pickle')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "toVG1EVMd5i9",
    "-R8J5NSed5jL"
   ],
   "name": "Heat Conduction - Direct - Dirichlet aman.ipynb",
   "provenance": [
    {
     "file_id": "1DquI6-opM6DDVTGby5XDaQdDuZQRlcl1",
     "timestamp": 1643096956064
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
