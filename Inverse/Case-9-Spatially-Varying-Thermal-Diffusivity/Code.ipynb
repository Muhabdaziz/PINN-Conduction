{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLomUAvByF54"
   },
   "source": [
    "# **Preparation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7ReT07SyIqg"
   },
   "source": [
    "## **Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64526,
     "status": "ok",
     "timestamp": 1647241552384,
     "user": {
      "displayName": "muhamad kuroyuki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1bjUJcxjD9YfQtTUthqjbEtihULJ54H7RmBNu=s64",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "LJbmWzPJyMUZ",
    "outputId": "f42a0e72-db51-4055-af6f-2cc4c7b93448"
   },
   "outputs": [],
   "source": [
    "# Install\n",
    "!pip install PyDOE\n",
    "!pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1263,
     "status": "ok",
     "timestamp": 1647241553641,
     "user": {
      "displayName": "muhamad kuroyuki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1bjUJcxjD9YfQtTUthqjbEtihULJ54H7RmBNu=s64",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "-jTowqixnhvL"
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import timeit\n",
    "import math as m\n",
    "import scipy.interpolate\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from pyDOE import lhs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647241553642,
     "user": {
      "displayName": "muhamad kuroyuki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1bjUJcxjD9YfQtTUthqjbEtihULJ54H7RmBNu=s64",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "KgZ9q0wcyOYd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-59d6G_T3U7M"
   },
   "source": [
    "## **Class & Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jxmBZup8di5"
   },
   "source": [
    "### **PINN Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6501,
     "status": "ok",
     "timestamp": 1647241560138,
     "user": {
      "displayName": "muhamad kuroyuki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1bjUJcxjD9YfQtTUthqjbEtihULJ54H7RmBNu=s64",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "ETX5B15cY8aN"
   },
   "outputs": [],
   "source": [
    "class PinnVP:\n",
    "\n",
    "    def __init__(self, data, params, problem_type, exist_model=False, file_dir=\"\"):\n",
    "        # Initialize & Unpack Input data\n",
    "        self.problem_type = problem_type\n",
    "        self.unpack(data, params)\n",
    "        self.initialize_variables()\n",
    "\n",
    "        # Initialize Neural Network Computational Graph\n",
    "        # Weight & biases\n",
    "        if exist_model:\n",
    "            print(\"Loading NN parameters ...\")\n",
    "            self.weights, self.biases = self.load_model(file_dir)\n",
    "        else:\n",
    "            self.weights, self.biases = self.initialize_network(lyr=self.layers)\n",
    "                 \n",
    "        if problem_type == \"Inverse\":\n",
    "            self.weights_2, self.biases_2 = self.initialize_network(lyr=self.layers_B)\n",
    "\n",
    "        # Placeholder & Graph\n",
    "        # Placeholder (where we put input)\n",
    "        self.initialize_placeholders()\n",
    "\n",
    "        # Computational graph of Physics-Informed\n",
    "        self.graph_network()\n",
    "\n",
    "        # Computational graph of loss\n",
    "        self.graph_loss()\n",
    "\n",
    "        # Optimizers\n",
    "        self.initialize_optimizers()\n",
    "\n",
    "        # Session\n",
    "        self.initialize_session()\n",
    "\n",
    "    def callback(self, loss_test, loss_total, loss_collo, loss_meu, loss_init):\n",
    "        self.count += 1\n",
    "        self.loss_test_log.append(loss_test)\n",
    "        self.loss_total_log.append(loss_total)\n",
    "        self.loss_collo_log.append(loss_collo)\n",
    "        self.loss_meu_log.append(loss_meu)\n",
    "        self.loss_init_log.append(loss_init)\n",
    "        \n",
    "        if self.count % self.verboses_newton == 0:    \n",
    "            print(\"iter: %d, Loss Test: %.4e, Loss Total: %.4e, Loss Collo: %.4e, Loss Measurements: %.4e, Loss Init: %.4e\" %\n",
    "                 (self.count, loss_test, loss_total, loss_collo, loss_meu, loss_init))\n",
    "            \n",
    "    def normalize_input_data(self):\n",
    "        # Normalize data\n",
    "        x_c = self.normalize_data(data=self.x_c, axis=\"x\")\n",
    "        t_c = self.normalize_data(data=self.t_c, axis=\"t\")\n",
    "        x_left = self.normalize_data(data=self.x_left, axis=\"x\")\n",
    "        t_left = self.normalize_data(data=self.t_left, axis=\"t\")\n",
    "        x_right = self.normalize_data(data=self.x_right, axis=\"x\")\n",
    "        t_right = self.normalize_data(data=self.t_right, axis=\"t\")\n",
    "        x_initial = self.normalize_data(data=self.x_initial, axis=\"x\")\n",
    "        t_initial = self.normalize_data(data=self.t_initial, axis=\"t\")\n",
    "        x_test = self.normalize_data(data=self.x_test, axis=\"x\")\n",
    "        t_test = self.normalize_data(data=self.t_test, axis=\"t\")\n",
    "\n",
    "        return x_c, t_c, x_left, t_left, x_right, t_right, x_initial, t_initial, x_test, t_test\n",
    "\n",
    "    def fit_newton(self):\n",
    "        # Change flag\n",
    "        self.newton_started = True\n",
    "        self.count += 0\n",
    "\n",
    "        # Normalize data\n",
    "        if len(self.loc_num) > 2:\n",
    "            (x_c, t_c, \n",
    "             x_left, t_left, \n",
    "             x_right, t_right,\n",
    "             x_initial, t_initial, \n",
    "             x_test, t_test) = self.normalize_input_data()\n",
    "            \n",
    "            x_meu = self.normalize_data(data=self.x_meu, axis=\"x\")\n",
    "            t_meu = self.normalize_data(data=self.t_meu, axis=\"t\")\n",
    "\n",
    "            # Create dictionary\n",
    "            tf_dict = {self.x_c_tf: x_c, self.t_c_tf: t_c,                              # collocation data\n",
    "                       self.x_left_tf: x_left, self.t_left_tf: t_left,                  # left data (pts)\n",
    "                       self.u_left_tf: self.u_left, \n",
    "                       self.x_right_tf: x_right, self.t_right_tf: t_right,              # right data\n",
    "                       self.u_right_tf: self.u_right,\n",
    "                       self.x_meu_tf: x_meu, self.t_meu_tf: t_meu,                      # measurement data\n",
    "                       self.u_meu_tf: self.u_meu,\n",
    "                       self.x_initial_tf: x_initial, self.t_initial_tf: t_initial,      # initial data\n",
    "                       self.u_initial_tf: self.u_initial, \n",
    "                       self.x_test_tf: x_test, self.t_test_tf: t_test,                  # test data\n",
    "                       self.u_test_tf:self.u_test, self.coef_bc_tf:self.coef_bc_val}\n",
    "        else:\n",
    "            (x_c, t_c, \n",
    "             x_left, t_left, \n",
    "             x_right, t_right,\n",
    "             x_initial, t_initial, \n",
    "             x_test, t_test) = self.normalize_input_data()\n",
    "\n",
    "            # Create dictionary\n",
    "            tf_dict = {self.x_c_tf: x_c, self.t_c_tf: t_c,                              # collocation data\n",
    "                       self.x_left_tf: x_left, self.t_left_tf: t_left,                  # left data (pts)\n",
    "                       self.u_left_tf: self.u_left, \n",
    "                       self.x_right_tf: x_right, self.t_right_tf: t_right,              # right data\n",
    "                       self.u_right_tf: self.u_right,\n",
    "                       self.x_initial_tf: x_initial, self.t_initial_tf: t_initial,      # initial data\n",
    "                       self.u_initial_tf: self.u_initial, \n",
    "                       self.x_test_tf: x_test, self.t_test_tf: t_test,                  # test data\n",
    "                       self.u_test_tf:self.u_test, self.coef_bc_tf:self.coef_bc_val}\n",
    "\n",
    "        self.train_op_newton.minimize(self.sess,\n",
    "                                      feed_dict=tf_dict,\n",
    "                                      fetches=[self.loss_test, self.loss_total, \n",
    "                                              self.loss_collo, self.loss_meu, self.loss_initial],\n",
    "                                      loss_callback=self.callback)\n",
    "        \n",
    "    def graph_loss(self):\n",
    "        # Test\n",
    "        self.loss_test = tf.math.sqrt(tf.reduce_mean(tf.square(self.u_test_tf - self.u_test_pred)))\n",
    "\n",
    "        # Collocation points\n",
    "        self.loss_collo = tf.reduce_mean(tf.square(self.f_pred_u)) \n",
    "        \n",
    "        # Boundary\n",
    "        self.loss_left = tf.reduce_mean(tf.square(self.u_left_pred-self.u_left_tf)) \n",
    "        self.loss_right = tf.reduce_mean(tf.square(self.u_right_pred-self.u_right_tf))\n",
    "        self.loss_bound = (self.loss_left + self.loss_right)\n",
    "\n",
    "        # initial\n",
    "        self.loss_initial = tf.reduce_mean(tf.square(self.u_initial_pred-self.u_initial_tf)) \n",
    "        \n",
    "        if len(self.loc_num) > 2:\n",
    "            self.loss_meu = tf.reduce_mean(tf.square(self.u_meu_pred - self.u_meu_tf))\n",
    "            self.loss_meu = self.coef_bc_val*(self.loss_bound + self.loss_meu)\n",
    "        else:\n",
    "            self.loss_meu = self.coef_bc_val*self.loss_bound\n",
    "\n",
    "        # Total loss\n",
    "        self.loss_total = self.loss_collo + self.loss_meu + self.loss_initial\n",
    "\n",
    "    def graph_network(self):\n",
    "        if self.problem_type == \"Inverse\":\n",
    "            # Test data\n",
    "            (self.u_test_pred, _) = self.net_dnn(self.x_test_tf, self.t_test_tf)\n",
    "            # Predict data\n",
    "            (self.u_pred, self.lambda_pred) = self.net_dnn_pred(self.x_tf, self.t_tf, self.x2_tf)\n",
    "            # Collocation points\n",
    "            (self.f_pred_u) = self.net_physics(self.x_c_tf, self.t_c_tf)\n",
    "            # left\n",
    "            (self.u_left_pred, _) = self.net_dnn(self.x_left_tf, self.t_left_tf)\n",
    "            # right\n",
    "            (self.u_right_pred, _) = self.net_dnn(self.x_right_tf, self.t_right_tf)\n",
    "            if len(self.loc_num) > 2:\n",
    "                (self.u_meu_pred, _) = self.net_dnn(self.x_meu_tf, self.t_meu_tf)\n",
    "            # Initial\n",
    "            (self.u_initial_pred, _) = self.net_dnn(self.x_initial_tf, self.t_initial_tf)\n",
    "        else:\n",
    "            # Test data\n",
    "            (self.u_test_pred) = self.net_dnn(self.x_test_tf, self.t_test_tf)\n",
    "            # Predict data\n",
    "            (self.u_pred) = self.net_dnn(self.x_tf, self.t_tf)\n",
    "            # Collocation points\n",
    "            (self.f_pred_u) = self.net_physics(self.x_c_tf, self.t_c_tf)\n",
    "            # measurement\n",
    "            (self.u_meu_pred) = self.net_dnn(self.x_meu_tf, self.t_meu_tf)\n",
    "            # Initial\n",
    "            (self.u_initial_pred) = self.net_dnn(self.x_initial_tf, self.t_initial_tf)\n",
    "        \n",
    "    def load_model(self, file_dir):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(self.layers)\n",
    "        \n",
    "        with open(file_dir, 'rb') as f:\n",
    "            dnn_weights, dnn_biases = pickle.load(f)\n",
    "\n",
    "            # stored model mush has the same layers\n",
    "            assert num_layers == (len(dnn_weights)+1)\n",
    "\n",
    "            for num in range(0, num_layers-1):\n",
    "                W = tf.Variable(dnn_weights[num])\n",
    "                b = tf.Variable(dnn_biases[num])\n",
    "                weights.append(W)\n",
    "                biases.append(b)\n",
    "                print('Loaded NN parameters successfully ...')\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def initialize_network(self, lyr):\n",
    "        # Initialize\n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(lyr)\n",
    "        layers = lyr\n",
    "\n",
    "        # Create network\n",
    "        for lyr in range(num_layers-1):\n",
    "            # initialize weights from Xavier initialization\n",
    "            np.random.seed(self.random_seed)\n",
    "            W = self.xavier_init(size=[layers[lyr], \n",
    "                                       layers[lyr+1]])\n",
    "\n",
    "            # initialize biases = 0\n",
    "            np.random.seed(self.random_seed)\n",
    "            b = tf.Variable(tf.zeros([1, layers[lyr+1]],\n",
    "                                     dtype=tf.float32),\n",
    "                            dtype=tf.float32)\n",
    "\n",
    "            # Append generated weights & biases to the list\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def initialize_optimizers(self):\n",
    "        if self.problem_type == \"Inverse\":\n",
    "            variable_list = self.weights + self.biases + self.weights_2 + self.biases_2 \n",
    "        else:\n",
    "            variable_list = self.weights + self.biases\n",
    "        self.train_op_newton = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "                                    self.loss_total,\n",
    "                                    var_list = variable_list,\n",
    "                                    method = \"L-BFGS-B\",\n",
    "                                    options = {\"maxiter\": 100000,\n",
    "                                               \"maxfun\": 100000,\n",
    "                                               \"maxcor\": 50,\n",
    "                                               \"maxls\": 50,\n",
    "                                               \"ftol\": 1*np.finfo(float).eps})\n",
    "\n",
    "    def initialize_placeholders(self):\n",
    "        self.coef_bc_tf = tf.placeholder(tf.float32, shape=self.coef_bc_val.shape)\n",
    "\n",
    "        # Test data\n",
    "        self.x_test_tf = tf.placeholder(tf.float32, shape=[None, self.x_test.shape[1]])\n",
    "        self.t_test_tf = tf.placeholder(tf.float32, shape=[None, self.t_test.shape[1]])\n",
    "        self.u_test_tf = tf.placeholder(tf.float32, shape=[None, self.u_test.shape[1]])\n",
    "        \n",
    "        # Predict data\n",
    "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x_c.shape[1]])\n",
    "        self.x2_tf = tf.placeholder(tf.float32, shape=[None, self.x_c.shape[1]])\n",
    "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t_c.shape[1]])\n",
    "\n",
    "        # Collocation data\n",
    "        self.x_c_tf = tf.placeholder(tf.float32, shape=[None, self.x_c.shape[1]])\n",
    "        self.t_c_tf = tf.placeholder(tf.float32, shape=[None, self.t_c.shape[1]])\n",
    "\n",
    "        # Boundary data\n",
    "        # left\n",
    "        self.x_left_tf = tf.placeholder(tf.float32, shape=[None, self.x_left.shape[1]])\n",
    "        self.t_left_tf = tf.placeholder(tf.float32, shape=[None, self.t_left.shape[1]])\n",
    "        self.u_left_tf = tf.placeholder(tf.float32, shape=[None, self.u_left.shape[1]])\n",
    "        # self.v_left_tf = tf.placeholder(tf.float32, shape=[None, self.v_left.shape[1]])\n",
    "\n",
    "        # right\n",
    "        self.x_right_tf = tf.placeholder(tf.float32, shape=[None, self.x_right.shape[1]])\n",
    "        self.t_right_tf = tf.placeholder(tf.float32, shape=[None, self.t_right.shape[1]])\n",
    "        self.u_right_tf = tf.placeholder(tf.float32, shape=[None, self.u_right.shape[1]])\n",
    "        \n",
    "        if len(self.loc_num) > 2:\n",
    "            self.x_meu_tf = tf.placeholder(tf.float32, shape=[None, self.x_meu.shape[1]])\n",
    "            self.t_meu_tf = tf.placeholder(tf.float32, shape=[None, self.t_meu.shape[1]])\n",
    "            self.u_meu_tf = tf.placeholder(tf.float32, shape=[None, self.u_meu.shape[1]])\n",
    "        \n",
    "        # initial\n",
    "        self.x_initial_tf = tf.placeholder(tf.float32, shape=[None, self.x_initial.shape[1]])\n",
    "        self.t_initial_tf = tf.placeholder(tf.float32, shape=[None, self.t_initial.shape[1]])\n",
    "        self.u_initial_tf = tf.placeholder(tf.float32, shape=[None, self.u_initial.shape[1]])\n",
    "\n",
    "    def initialize_session(self):\n",
    "        tf_config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                                   log_device_placement=True)\n",
    "        self.sess = tf.Session(config=tf_config)\n",
    "        # self.sess = tf.InteractiveSession(config=tf_config)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def initialize_variables(self):\n",
    "        # For saving loss\n",
    "        self.loss_total_log = []\n",
    "        self.loss_collo_log = []\n",
    "        self.loss_meu_log = []\n",
    "        self.loss_init_log  = []\n",
    "        self.loss_test_log = []\n",
    "        self.count = 0\n",
    "        self.newton_started = False\n",
    "\n",
    "    def net_dnn(self, x, t):\n",
    "        # Find results\n",
    "        X = tf.concat([x, t], 1)\n",
    "        \n",
    "\n",
    "        T = self.net_forward(X, self.weights, self.biases)\n",
    "        if self.problem_type == \"Inverse\":\n",
    "            lambda_ = self.net_forward(x, self.weights_2, self.biases_2)\n",
    "\n",
    "            return T, lambda_   \n",
    "        else:\n",
    "            return T\n",
    "        \n",
    "    def net_dnn_pred(self, x1, y1, x2):\n",
    "        X = tf.concat([x1, y1], 1)\n",
    "        \n",
    "        T = self.net_forward(X, self.weights, self.biases)\n",
    "        lambda_ = self.net_forward(x2, self.weights_2, self.biases_2)\n",
    "        \n",
    "        return T, lambda_\n",
    "\n",
    "    def net_forward(self, X, weights, biases):\n",
    "        num_layers = len(weights)+1\n",
    "        H = X\n",
    "\n",
    "        for lyr in range(num_layers-2):\n",
    "            W = weights[lyr]\n",
    "            b = biases[lyr]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "\n",
    "        return Y\n",
    "\n",
    "    def net_physics(self, x, t):\n",
    "        # Find results from DNN\n",
    "        if self.problem_type == \"Inverse\":\n",
    "            T, lambda_ = self.net_dnn(x, t)\n",
    "        else:\n",
    "            T = self.net_dnn(x, t)\n",
    "\n",
    "        # Temperature gradient\n",
    "        T_x = tf.gradients(T, x)[0] / self.sigma_x\n",
    "        T_xx = tf.gradients(T_x, x)[0] / self.sigma_x\n",
    "        T_t = tf.gradients(T, t)[0] / self.sigma_t\n",
    "        \n",
    "        if self.problem_type == \"Inverse\":\n",
    "            lambda_x = tf.gradients(lambda_, x)[0] / self.sigma_x\n",
    "            \n",
    "        # Physics error\n",
    "        \n",
    "        x = x*self.sigma_x + self.mu_x\n",
    "        t = t*self.sigma_t + self.mu_t\n",
    "        \n",
    "        h = 50*(((x - 0.6)**2)*(1 - t)*tf.exp(-t) \\\n",
    "            - (2 + (0.5 - 4*(x - 0.3)*(x - 0.6))*tf.exp(-4*(x - 0.3)**2))*t*tf.exp(-t))\n",
    "        if self.problem_type == \"Inverse\":\n",
    "            f = T_t - tf.multiply(lambda_x,T_x) - tf.multiply(lambda_,T_xx) - h            \n",
    "        else:\n",
    "            lambda_ = 1 + 0.25*tf.exp(-4*(x - 0.3)**2)\n",
    "            lambda_x = (-1/5)*(10*x - 3)*tf.exp(-4*(x - 0.3)**2)\n",
    "            f = T_t - lambda_x*T_x - lambda_*T_xx - h\n",
    "                \n",
    "        return f\n",
    "    \n",
    "    def normalize_data(self, data, axis):\n",
    "        if axis == \"x\":\n",
    "            normalized_data = (data - self.mu_x) / self.sigma_x\n",
    "        elif axis == \"t\":\n",
    "            normalized_data = (data - self.mu_t) / self.sigma_t\n",
    "\n",
    "        return normalized_data\n",
    "\n",
    "    def predict(self, x_star, t_star, x2_star):\n",
    "        # Prepare the input\n",
    "        x_star = (x_star - self.mu_x) / self.sigma_x\n",
    "        t_star = (t_star - self.mu_t) / self.sigma_t\n",
    "        if self.problem_type == \"Inverse\":\n",
    "            x2_star = (x2_star - self.mu_x) / self.sigma_x\n",
    "            tf_dict = {self.x_tf:x_star, self.t_tf:t_star, self.x2_tf:x2_star}\n",
    "        else:\n",
    "            tf_dict = {self.x_tf:x_star, self.t_tf:t_star}\n",
    "\n",
    "        # Predict\n",
    "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
    "\n",
    "        if self.problem_type == \"Inverse\":\n",
    "            lambda_ = self.sess.run(self.lambda_pred, tf_dict)\n",
    "            return u_star, lambda_\n",
    "        else:\n",
    "            return u_star        \n",
    "\n",
    "    def save_loss(self, file_dir):\n",
    "        loss_test = np.array(self.loss_test_log)\n",
    "        loss_data = np.column_stack((self.loss_total_log, \n",
    "                                     self.loss_collo_log,\n",
    "                                     self.loss_meu_log,\n",
    "                                     self.loss_init_log,\n",
    "                                     loss_test))\n",
    "        loss_df = pd.DataFrame(loss_data, columns=[\"total\", \"collo\", \"measurement\", \"initial\", \"error_u\"])\n",
    "        joblib.dump(loss_df, file_dir)\n",
    "\n",
    "    def save_model(self, file_dir):\n",
    "        weights = self.sess.run(self.weights)\n",
    "        biases = self.sess.run(self.biases)\n",
    "\n",
    "        with open(file_dir, 'wb') as f:\n",
    "            pickle.dump([weights, biases], f)\n",
    "            print(\"Save NN parameters successfully...\")\n",
    "\n",
    "    def unpack(self, data, params):\n",
    "        # Initialize\n",
    "        self.data = data\n",
    "        self.params = params\n",
    "\n",
    "        # Unpack Parameters\n",
    "        # Data-Boundary\n",
    "        self.lb = params[\"data\"][\"lb\"]\n",
    "        self.ub = params[\"data\"][\"ub\"]\n",
    "        \n",
    "        self.random_seed = self.data[\"train\"][\"seed\"]\n",
    "        \n",
    "        # Data-Collocation\n",
    "        self.x_c = data[\"train\"][\"collo\"][:, 0:1]\n",
    "        self.t_c = data[\"train\"][\"collo\"][:, 1:2]\n",
    "        self.mu_x = data[\"train\"][\"mu_x\"]\n",
    "        self.mu_t = data[\"train\"][\"mu_t\"]\n",
    "        self.sigma_x = data[\"train\"][\"sigma_x\"]\n",
    "        self.sigma_t = data[\"train\"][\"sigma_t\"]\n",
    "        \n",
    "        # measurements\n",
    "        self.loc_num = params[\"data\"][\"loc\"]\n",
    "        self.meu_num = params[\"data\"][\"meu\"]\n",
    "        meu = np.zeros(shape=(1, 3))\n",
    "        for i in range(1, len(self.loc_num)-1):\n",
    "            meu = np.concatenate((meu, self.data[\"train\"][f\"loc={self.loc_num[i]}\"]),axis=0)            \n",
    "        meu = meu[1:,:]\n",
    "        self.x_meu = meu[:, 0:1]\n",
    "        self.t_meu = meu[:, 1:2]\n",
    "        self.u_meu = meu[:, 2:3]\n",
    "        \n",
    "        self.x_left = self.data[\"train\"][f\"loc=0.0\"][:, 0:1]\n",
    "        self.t_left = self.data[\"train\"][f\"loc=0.0\"][:, 1:2]\n",
    "        self.u_left = self.data[\"train\"][f\"loc=0.0\"][:, 2:3]\n",
    "        \n",
    "        self.x_right = self.data[\"train\"][f\"loc=1.0\"][:, 0:1]\n",
    "        self.t_right = self.data[\"train\"][f\"loc=1.0\"][:, 1:2]\n",
    "        self.u_right = self.data[\"train\"][f\"loc=1.0\"][:, 2:3]\n",
    "\n",
    "        \n",
    "        # Data-initial\n",
    "        self.x_initial = data[\"train\"][\"initial\"][:, 0:1]\n",
    "        self.t_initial = data[\"train\"][\"initial\"][:, 1:2]\n",
    "        self.u_initial = data[\"train\"][\"initial\"][:, 2:3]\n",
    "\n",
    "        # Data-Test\n",
    "        self.x_test = data[\"test\"][:, 0:1]\n",
    "        self.t_test = data[\"test\"][:, 1:2]\n",
    "        self.u_test = data[\"test\"][:, 2:3]\n",
    "\n",
    "        # Network\n",
    "        self.layers = params[\"network\"][\"layers\"]\n",
    "        if self.problem_type == \"Inverse\":\n",
    "            self.layers_B = params[\"network\"][\"layers_B\"]\n",
    "        self.coef_bc_val = np.array(params[\"network\"][\"coef_bc\"])\n",
    "        self.verboses_newton = params[\"network\"][\"verboses_newton\"]\n",
    "\n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = np.sqrt(2 / (in_dim + out_dim))\n",
    "\n",
    "        # tf.set_random_seed(20)\n",
    "        np.random.seed(self.random_seed)\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], \n",
    "                                               stddev=xavier_stddev, \n",
    "                                               dtype=tf.float32,\n",
    "                                               seed=40), \n",
    "                           dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Cases*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1240,
     "status": "ok",
     "timestamp": 1647241561373,
     "user": {
      "displayName": "muhamad kuroyuki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1bjUJcxjD9YfQtTUthqjbEtihULJ54H7RmBNu=s64",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "SBoYWjnT8iQt"
   },
   "outputs": [],
   "source": [
    "class CasesChannel:\n",
    "\n",
    "    def __init__(self, add_noise=False, save_fig=False):\n",
    "        self.add_noise = add_noise\n",
    "        self.save_fig = save_fig\n",
    "        self.data = {}\n",
    "\n",
    "    # def analytics_solution(self, y):\n",
    "    def analytics_solution(self, x, t):\n",
    "        T_ = 50*((x - 0.6)**2)*t*np.exp(-t)\n",
    "\n",
    "        return T_\n",
    "\n",
    "    def generate_bc(self, loc, n):\n",
    "        x = loc*self.ub[0]*np.ones((n,1))\n",
    "        np.random.seed(self.random_seed)  \n",
    "        t = lhs(1,n)*self.ub[1]\n",
    "        T = 50*((x - 0.6)**2)*t*np.exp(-t)\n",
    "\n",
    "        # concat data\n",
    "        bc_datas = np.concatenate((x, t, T), axis=1)\n",
    "            \n",
    "        return bc_datas \n",
    "        \n",
    "    def generate_ic(self):\n",
    "        n = self.n_initial\n",
    "        np.random.seed(self.random_seed)     \n",
    "        x = lhs(1,n)*self.ub[0]\n",
    "        t = 0.0*lhs(1,n)\n",
    "        T = 0.0*lhs(1,n)\n",
    "\n",
    "        # concat data\n",
    "        ic_datas = np.concatenate((x, t, T), axis=1)\n",
    "        print(ic_datas[:,0].shape)\n",
    "        return ic_datas \n",
    "        \n",
    "    def generate_collo(self):\n",
    "        # unpack\n",
    "        n = self.n_collo\n",
    "        lb = self.lb\n",
    "        ub = self.ub\n",
    "\n",
    "        # create points\n",
    "        np.random.seed(self.random_seed)\n",
    "        collo_pts = lb + (ub-lb)*lhs(2, n, criterion=None)\n",
    "\n",
    "        self.mu_X, self.sigma_X = collo_pts.mean(0), collo_pts.std(0)\n",
    "        self.mu_x, self.sigma_x = self.mu_X[0], self.sigma_X[0]\n",
    "        self.mu_t, self.sigma_t = self.mu_X[1], self.sigma_X[1]\n",
    "                \n",
    "        return collo_pts \n",
    "\n",
    "    def generate_train_data(self, param):\n",
    "        \n",
    "        # Unpack parameters\n",
    "        self.unpack(param)\n",
    "        \n",
    "\n",
    "        # Generate points\n",
    "        # Generate boundary conditions data \n",
    "        init_cond = self.generate_ic()\n",
    "        \n",
    "        loc = self.loc_num   # location measurements --> e.g 0%, 50%, 100%\n",
    "        meu = self.meu_num   # Measurements --> 50, 100, 150..\n",
    "        \n",
    "        bc = []        \n",
    "        self.data[\"train\"] = {}\n",
    "        \n",
    "        for i in range (0, len(loc)):\n",
    "            mea = self.generate_bc(loc[i],int(meu[i]))\n",
    "            bc.append(mea)\n",
    "            self.data[\"train\"][f\"loc={loc[i]}\"] = bc[i]\n",
    "            \n",
    "        mea = np.zeros(shape=(1, 3))\n",
    "        for i in range(0, len(self.loc_num) ):\n",
    "            mea = np.concatenate((mea, self.data[\"train\"][f\"loc={self.loc_num[i]}\"]), axis=0)\n",
    "            \n",
    "        mea = mea[1:,:]\n",
    "        T = mea[:, 2:3]\n",
    "        T_init = init_cond[:,2:3]\n",
    "            \n",
    "        # noise addition\n",
    "        if self.add_noise:\n",
    "            noise = self.noise_level\n",
    "            maxT = max([np.max(T), np.max(T_init)])\n",
    "            sigma = noise * maxT\n",
    "            print(f\"T max: {maxT}\")\n",
    "            for i in  range(0, len(self.loc_num)):\n",
    "                T = self.data[\"train\"][f\"loc={loc[i]}\"][:,2:3]\n",
    "                np.random.seed(self.random_seed)\n",
    "                T = T + sigma*np.random.randn(T.shape[0],1)\n",
    "                self.data[\"train\"][f\"loc={loc[i]}\"][:,2:3] = T\n",
    "            \n",
    "            random_noise_init = sigma*np.random.randn(T_init.shape[0], 1)\n",
    "            \n",
    "            T_init = T_init + random_noise_init\n",
    "                \n",
    "        self.data[\"train\"][\"initial\"] = np.concatenate((init_cond[:, 0:2], T_init), axis=1)\n",
    "            \n",
    "\n",
    "        # Generate collocations points data\n",
    "        collo_ = self.generate_collo()\n",
    "\n",
    "        # Pack data\n",
    "        self.data[\"train\"][\"collo\"] = collo_\n",
    "        self.data[\"train\"][\"mu_x\"] = self.mu_x\n",
    "        self.data[\"train\"][\"sigma_x\"] = self.sigma_x\n",
    "        self.data[\"train\"][\"mu_t\"] = self.mu_t\n",
    "        self.data[\"train\"][\"sigma_t\"] = self.sigma_t\n",
    "        self.data[\"train\"][\"seed\"] = self.random_seed\n",
    "\n",
    "    def generate_test_data(self, param):\n",
    "        # Unpack parameters\n",
    "        self.unpack(param)\n",
    "\n",
    "        # Generate points\n",
    "        length_ = self.ub - self.lb\n",
    "        min_length_ = np.argmin(length_)\n",
    "        frac_ = max(length_) / min(length_)\n",
    "        n_test_1 = int(frac_ * self.n_test)\n",
    "\n",
    "        # Create grid\n",
    "        if min_length_ == 0:\n",
    "            self.n_x = self.n_test\n",
    "            self.n_t = n_test_1\n",
    "        else:\n",
    "            self.n_x = n_test_1\n",
    "            self.n_t = self.n_test\n",
    "            \n",
    "            \n",
    "        np.random.seed(self.random_seed)    #INI BEDA\n",
    "        x_ = lhs(1,self.n_x)*self.ub[0]     #INI BEDA\n",
    "        t_ = np.linspace(self.lb[1], self.ub[1], num=int(self.n_t))\n",
    "        X, T = np.meshgrid(x_, t_)\n",
    "        X_flat = X.flatten()[:,None]\n",
    "        T_flat = T.flatten()[:,None]\n",
    "        U_ = self.analytics_solution(X_flat, T_flat)\n",
    "        \n",
    "        self.data[\"test\"] = np.column_stack((X_flat, T_flat, U_))\n",
    "        \n",
    "    def plot(self):\n",
    "        # unpack data\n",
    "        collo_ = self.data[\"train\"][\"collo\"]\n",
    "        meu = []\n",
    "        for i in range(0, len(self.loc_num)):\n",
    "            meu.append(self.data[\"train\"][f\"loc={self.loc_num[i]}\"])\n",
    "        initial_ = self.data[\"train\"][\"initial\"]\n",
    "\n",
    "        # PLOT: points distribution\n",
    "        # Properties\n",
    "        plt.rc('text', usetex=True)\n",
    "        plt.rc('font', family='serif')\n",
    "\n",
    "        # Plot\n",
    "        fig_w = 15\n",
    "        fig_h = 15\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(fig_w, fig_h), constrained_layout=True, dpi=300)\n",
    "\n",
    "        ax.plot([self.lb[0], self.ub[0]], [self.lb[1], self.lb[1]], 'k')\n",
    "        ax.plot([self.lb[0], self.ub[0]], [self.ub[1], self.ub[1]], 'k')\n",
    "        ax.plot([self.lb[0], self.lb[0]], [self.ub[1], self.lb[1]], 'k')\n",
    "        ax.plot([self.ub[0], self.ub[0]], [self.ub[1], self.lb[1]], 'k')\n",
    "\n",
    "        ax.scatter(collo_[:,0:1], collo_[:,1:2], marker='.', alpha=0.7, c='grey', label='Collo')\n",
    "        for i in range(0, len(self.loc_num)):\n",
    "            ax.scatter(meu[i][:,0:1], meu[i][:,1:2], marker='.', alpha=0.7,  label=f'Measurements, $x/L$={np.round(self.loc_num[i],2)}')\n",
    "        ax.scatter(initial_[:,0:1], initial_[:,1:2], marker='.', alpha=1.0, c='b', label='IC')\n",
    "\n",
    "        ax.set_title(\"Points distribution\", fontsize=40)\n",
    "        ax.set_xlabel(\"$x$ (m)\", fontsize=35)\n",
    "        ax.set_ylabel(\"$t$ (s)\", fontsize=35)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=30)\n",
    "        ax.legend(fontsize=30, loc=4)\n",
    "        ax.grid(linestyle=\"--\")\n",
    "        ax.set_xlim(self.lb[0], self.ub[0])\n",
    "        ax.set_ylim(self.lb[1], self.ub[1])\n",
    "\n",
    "        if self.save_fig:\n",
    "            fig.savefig(\"fig_point_distribution.eps\", format=\"eps\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        if self.save_fig:\n",
    "            fig.savefig(\"fig_references.eps\", format=\"eps\")\n",
    "        plt.show()\n",
    "\n",
    "    def unpack(self, param):\n",
    "        # # Constant\n",
    "        # Bound\n",
    "        self.lb = param[\"data\"][\"lb\"]\n",
    "        self.ub = param[\"data\"][\"ub\"]\n",
    "\n",
    "        # Discretizations\n",
    "        self.n_collo = param[\"data\"][\"n_collo\"]\n",
    "        self.n_initial = param[\"data\"][\"n_initial\"]\n",
    "        self.n_test = param[\"data\"][\"n_test\"]\n",
    "        self.random_seed = param[\"data\"][\"seed\"]\n",
    "        self.noise_level = param[\"data\"][\"noise\"]\n",
    "        self.loc_num = param[\"data\"][\"loc\"]\n",
    "        self.meu_num = param[\"data\"][\"meu\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpZLqlZx8isK"
   },
   "source": [
    "### **Post Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2869,
     "status": "ok",
     "timestamp": 1647244235451,
     "user": {
      "displayName": "muhamad kuroyuki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1bjUJcxjD9YfQtTUthqjbEtihULJ54H7RmBNu=s64",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "nZwRPWz48kf4"
   },
   "outputs": [],
   "source": [
    "class PostChannel:\n",
    "\n",
    "    def __init__(self, model, params, save_fig=False):\n",
    "        self.save_fig = save_fig\n",
    "        self.unpack(model, params)\n",
    "\n",
    "    def analytics_solution(self, x, t):\n",
    "        T_ = 50*((x - 0.6)**2)*t*np.exp(-t)\n",
    "\n",
    "        return T_\n",
    "    \n",
    "    def lambda_solution(self, x):\n",
    "        lambda_ = 1 + 0.25*np.exp(-4*(x - 0.3)**2)\n",
    "        \n",
    "        return lambda_\n",
    "    \n",
    "    def calculate_pinn(self):\n",
    "        if self.model.problem_type == \"Inverse\":\n",
    "            self.u_pinn, self.lambda_pred = self.model.predict(self.X_flat, self.T_flat, self.x.flatten()[:,None])\n",
    "            self.lambda_ = self.lambda_pred\n",
    "        else:\n",
    "            self.u_pinn = self.model.predict(self.X_flat, self.T_flat, self.x.flatten()[:,None])\n",
    "        self.x_pinn_ = self.X_flat.reshape(self.n_t, self.n_x)\n",
    "        self.t_pinn_ = self.T_flat.reshape(self.n_t, self.n_x)\n",
    "        self.u_pinn_ = self.u_pinn.reshape(self.n_t, self.n_x)\n",
    "\n",
    "    def calculate_error(self, n_data):\n",
    "        x_test = self.model.x_test \n",
    "        t_test = self.model.t_test\n",
    "\n",
    "        # Prediction\n",
    "        u_pinn = self.u_pinn\n",
    "        u_analytic = self.analytics_solution(self.X_flat, self.T_flat)\n",
    "        u_test = u_analytic\n",
    "\n",
    "        delta_u = np.abs(u_pinn - u_test)\n",
    "        #  Absolute error with n_x and n_t points\n",
    "        self.abs_err_u = np.sum(delta_u)/(self.n_x * self.n_t)\n",
    "\n",
    "        rel_err_u_ij = delta_u/u_test\n",
    "        # Relative error with n_x and n_t points\n",
    "        self.rel_err_u = np.sum(rel_err_u_ij)/(self.n_x * self.n_t)\n",
    "\n",
    "        print(f\"- Absolute Error: {self.abs_err_u:5f}\")\n",
    "        print(f\"- Relative Error (%): {self.rel_err_u*100:5f}\")\n",
    "\n",
    "        if self.model.problem_type == \"Inverse\":\n",
    "            self.lambda_ref = self.lambda_solution(self.x.flatten()[:,None])\n",
    "            self.delta_lambda = np.abs(self.lambda_pred - self.lambda_ref) \n",
    "            self.rel_lambda = np.abs(self.lambda_pred - self.lambda_ref) / self.lambda_ref\n",
    "\n",
    "            self.abs_err_lambda = np.sum(self.delta_lambda) / (self.x.shape[0])\n",
    "            self.rel_err_lambda = np.sum(self.rel_lambda) / (self.x.shape[0])\n",
    "            \n",
    "            delta_squared = self.delta_lambda**2\n",
    "            self.rmse_lambda = np.sqrt(np.sum(delta_squared) / (self.x.shape[0]))\n",
    "            \n",
    "            self.mean_lambda_ref = np.mean(self.lambda_ref)\n",
    "            self.SST = np.sum((self.lambda_ref - self.mean_lambda_ref)**2)\n",
    "            self.SSE = np.sum(delta_squared)\n",
    "            self.R2 = 1 - self.SSE / self.SST\n",
    "\n",
    "#             print(f\"sum delta lambda: {np.sum(self.delta_lambda)}\")\n",
    "#             print(f\"sum rel lambda: {np.sum(self.rel_lambda)}\")\n",
    "\n",
    "            print(f\"Absolute Error Lambda: {self.abs_err_lambda:5f}\")\n",
    "            print(f\"Relative Error Lambda (%): {self.rel_err_lambda*100:5f}\")\n",
    "            \n",
    "            print(f\"RMSE lambda: {self.rmse_lambda:5f}\")\n",
    "            print(f\"R2 (%): {self.R2*100:5f}\")\n",
    "        \n",
    "\n",
    "        return x_test, t_test, u_pinn, u_test\n",
    "\n",
    "    def create_test_data(self):\n",
    "        # Find fraction\n",
    "        length_ = self.ub - self.lb\n",
    "        min_length_ = np.argmin(length_)\n",
    "        frac_ = max(length_) / min(length_)\n",
    "        n_test_1 = int(frac_ * self.n_test)\n",
    "\n",
    "        # Create grid\n",
    "        if min_length_ == 0:\n",
    "            self.n_x = self.n_test\n",
    "            self.n_t = n_test_1\n",
    "        else:\n",
    "            self.n_x = n_test_1\n",
    "            self.n_t = self.n_test\n",
    "\n",
    "        self.x = np.linspace(self.lb[0], self.ub[0], num=self.n_x)\n",
    "        self.t = np.linspace(self.lb[1], self.ub[1], num=self.n_t)\n",
    "        self.X, self.T = np.meshgrid(self.x, self.t)\n",
    "        self.X_flat = self.X.flatten()[:, None]\n",
    "        self.T_flat = self.T.flatten()[:, None]\n",
    "\n",
    "    def display_loss(self):\n",
    "        # SET\n",
    "        plt.rc('text', usetex=True)\n",
    "        plt.rc('font', family='serif')\n",
    "\n",
    "        # Extract data\n",
    "        loss_total = self.model.loss_total_log\n",
    "        loss_collo = self.model.loss_collo_log\n",
    "        loss_meu = self.model.loss_meu_log\n",
    "        loss_init = self.model.loss_init_log\n",
    "        loss_test = self.model.loss_test_log\n",
    "\n",
    "        # Status\n",
    "        if self.model.newton_started:\n",
    "            run_status = \"newton\"\n",
    "        else:\n",
    "            run_status = \"none\"\n",
    "\n",
    "        # Prepare\n",
    "        iter_total = []\n",
    "\n",
    "        if run_status == \"newton\":\n",
    "            n_total = len(loss_total)\n",
    "\n",
    "            for i in range(n_total):\n",
    "                iter_total.append(i)\n",
    "        else:\n",
    "            n_total = 0\n",
    "        \n",
    "        # PLOT History\n",
    "        if run_status != \"none\":\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 6), constrained_layout=True, dpi=300)\n",
    "            ax.plot(iter_total, loss_total, \"r\", linestyle=\"solid\", label=\"Physical Loss\")\n",
    "            ax.plot(iter_total, loss_collo, \"g\", linestyle=\"dashdot\", label=\"Collocation Loss\")\n",
    "            ax.plot(iter_total, loss_meu, \"b\", linestyle=\"dotted\", label=\"Measurement Loss\")\n",
    "            ax.plot(iter_total, loss_init, 'purple',linestyle='solid', label='Initial Loss')\n",
    "            ax.plot(iter_total, loss_test, \"black\", linestyle=\"dashed\", label=\"Test Error\")\n",
    "\n",
    "            ax.set_xlim(0, iter_total[-1])\n",
    "            ax.set_yscale(\"log\")\n",
    "            ax.set_xlabel(\"Iterations\", fontsize=12)\n",
    "            ax.set_ylabel(\"RMSE\", fontsize=12)\n",
    "            ax.grid(linestyle=\"--\")\n",
    "            ax.legend(fontsize=10)\n",
    "            ax.set_title('Loss History (Log Scale)', fontsize=17)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "            # save figure\n",
    "            if self.save_fig:\n",
    "                fig.savefig(\"fig_loss_history.eps\", format=\"eps\")\n",
    "            plt.show()\n",
    "        \n",
    "        print(f\"- Last Iterations: {iter_total[-1]}\")\n",
    "        \n",
    "    def display_contour(self):\n",
    "        # FIND: PINN results\n",
    "        self.create_test_data()\n",
    "        self.calculate_pinn()\n",
    "\n",
    "        # PLOT CONTOUR\n",
    "        fig_h = 3 \n",
    "        fig_w = 10\n",
    "\n",
    "        if self.model.problem_type == \"Inverse\":\n",
    "            x_, y_, u_pinn, u_test = self.calculate_error(n_data = self.n_test)\n",
    "            # PLOT: comparison\n",
    "            \n",
    "            self.plot_comparison(x=self.x, t=self.t, \n",
    "                                phi_pinn=self.lambda_pred, \n",
    "                                phi_analytics=self.lambda_ref, \n",
    "                                fig_w=fig_w, fig_h=fig_h)\n",
    "            v_min_lambda = (min(self.rel_lambda))\n",
    "            v_max_lambda = (max(self.rel_lambda))\n",
    "            self.plot_countour(x=self.X, t=self.T, \n",
    "                                      x_flat=self.X_flat, t_flat=self.T_flat,\n",
    "                                      phi=self.u_pinn, phi_=self.u_pinn.reshape(self.n_t, self.n_x),\n",
    "                                      vmin=min(u_pinn), vmax=max(u_pinn),\n",
    "                                      fig_w=fig_w, fig_h=fig_h)\n",
    "        else:\n",
    "            self.plot_countour(x=self.X, t=self.T, \n",
    "                                      x_flat=self.X_flat, t_flat=self.T_flat,\n",
    "                                      phi=self.u_pinn, phi_=self.u_pinn.reshape(self.n_t, self.n_x),\n",
    "                                      vmin=min(u_test), vmax=max(u_test),\n",
    "                                      fig_w=fig_w, fig_h=fig_h)\n",
    "        \n",
    "\n",
    "    def plot_comparison(self, x, t, phi_pinn, phi_analytics, fig_w, fig_h):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(fig_w, fig_h), dpi=100, constrained_layout=False)\n",
    "        ax.plot(x, phi_pinn, 'b', label=\"PINN Solution\", linewidth=4)\n",
    "        ax.plot(x, phi_analytics, '--r', label=\"Analytical Solution\", linewidth=4)\n",
    "\n",
    "        x_lim_min = min(np.min(phi_pinn), np.min(phi_analytics))\n",
    "        x_lim_max = max(np.max(phi_pinn), np.max(phi_analytics))\n",
    "        ax.set_ylim(x_lim_min, x_lim_max)\n",
    "        ax.set_xlim(self.lb[1], self.ub[1])\n",
    "        ax.set_xlabel(\"$x$ (m)\", fontsize=20)\n",
    "        ax.set_ylabel(\"$\\lambda$ (W/m\\u2103)\", fontsize=20)\n",
    "        ax.grid(linestyle=\"--\")\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.set_title(\"$\\lambda$ Comparison\", fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_countour(self, x, t, x_flat, t_flat, phi, phi_, vmin, vmax, fig_w, fig_h):\n",
    "        # Set\n",
    "        plt.rc('text', usetex=True)\n",
    "        plt.rc('font', family='serif')\n",
    "        \n",
    "        # Create plot\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(fig_w, fig_h), dpi=300, constrained_layout=False)\n",
    "\n",
    "        # Unpack\n",
    "        cf = ax.scatter(x_flat, t_flat, c=phi, \n",
    "                        alpha=1., edgecolors='none', cmap='jet', marker=\".\", s=50, vmin=vmin, vmax=vmax)\n",
    "        ax.set_xlim(self.lb[0], self.ub[0])\n",
    "        ax.set_ylim(self.lb[1], self.ub[1])\n",
    "        \n",
    "        ax.set_title(f'$T(x,t)$ PINN Solution', fontsize=20)\n",
    "        \n",
    "        ax.set_xlabel('$x$ (m)', fontsize=20)\n",
    "        ax.set_ylabel('$t$ (m)', fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        ax.contour(x, t, phi_, colors='k', linewidths=0.2, levels=50)\n",
    "        \n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        cb = fig.colorbar(cf, cax=cax)\n",
    "        ticks = np.linspace(vmin, vmax, 3)\n",
    "        ticks = np.round(ticks, 2)\n",
    "        cb.set_ticks(ticks)\n",
    "        cb.ax.tick_params(labelsize=16)\n",
    "\n",
    "        # Analytical Solution contour\n",
    "        T = self.analytics_solution(x_flat, t_flat) \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(fig_w, fig_h), dpi=300, constrained_layout=False)\n",
    "        vmin = min(T)\n",
    "        vmax = max(T)\n",
    "        cf = ax.scatter(x_flat, t_flat, c=T, alpha=1., edgecolors='none', cmap='jet', marker=\".\", s=50, vmin=vmin, vmax=vmax)\n",
    "        ax.set_xlim(self.lb[0], self.ub[0])\n",
    "        ax.set_ylim(self.lb[1], self.ub[1])\n",
    "\n",
    "        ax.set_title('$T(x,t)$ Analytical Solution', fontsize=20)\n",
    "\n",
    "        ax.set_xlabel('$x$ (m)', fontsize=20)\n",
    "        ax.set_ylabel('$t$ (m)', fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        ax.contour(x, t, self.analytics_solution(x, t), colors='k', linewidths=0.2, levels=50)\n",
    "\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        cb = fig.colorbar(cf, cax=cax)\n",
    "        ticks = np.linspace(vmin, vmax, 3)\n",
    "        ticks = np.round(ticks, 2)\n",
    "        cb.set_ticks(ticks)\n",
    "        cb.ax.tick_params(labelsize=16)\n",
    "\n",
    "        # save figure\n",
    "        if self.save_fig:\n",
    "            fig.savefig(f\"fig_{types}.eps\", format=\"eps\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_countour_lambda(self, x, t, x_flat, t_flat, phi, phi_, vmin, vmax, fig_w, fig_h):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(fig_w, fig_h), dpi=300, constrained_layout=False)\n",
    "\n",
    "        # Unpack\n",
    "        cf = ax.scatter(x_flat, t_flat, c=phi, \n",
    "                        alpha=1., edgecolors='none', cmap='jet', marker=\".\", s=50, vmin=vmin, vmax=vmax)\n",
    "        ax.set_xlim(self.lb[0], self.ub[0])\n",
    "        ax.set_ylim(self.lb[1], self.ub[1])\n",
    "        \n",
    "        ax.set_title('Relative Errors (x, t)', fontsize=30)\n",
    "        \n",
    "        ax.set_xlabel('$x$ (m)', fontsize=25)\n",
    "        ax.set_ylabel('$t$ (s)', fontsize=25)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        ax.contour(x, t, phi_, colors='k', linewidths=0.2, levels=50)\n",
    "        \n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        cb = fig.colorbar(cf, cax=cax)\n",
    "        ticks = np.linspace(vmin, vmax, 3)\n",
    "        ticks = np.round(ticks, 2)\n",
    "        cb.set_ticks(ticks)\n",
    "        cb.ax.tick_params(labelsize=16)\n",
    "\n",
    "    def unpack(self, model, params):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "\n",
    "        self.lb = params[\"data\"][\"lb\"]\n",
    "        self.ub = params[\"data\"][\"ub\"]\n",
    "        self.n_test = params[\"data\"][\"n_test\"]\n",
    "        self.coef_bc = params[\"network\"][\"coef_bc\"]\n",
    "        self.verboses_newton = params[\"network\"][\"verboses_newton\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaq_LJNqZCAR"
   },
   "source": [
    "# **RUN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1516,
     "status": "ok",
     "timestamp": 1647241564031,
     "user": {
      "displayName": "muhamad kuroyuki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1bjUJcxjD9YfQtTUthqjbEtihULJ54H7RmBNu=s64",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "c3WZht2MZX4N"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x\n",
    "# import tensorflow as tf\n",
    "# device_name = tf.test.gpu_device_name()\n",
    "# if device_name != '/device:GPU:0':\n",
    "#   raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "\n",
    "# Set GPU to tensorflow session\n",
    "with tf.device('/device:GPU:2'):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    # session = tf.InteractiveSession(config=config)\n",
    "    session = tf.Session(config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4p2TyP64ZHoZ"
   },
   "source": [
    "## **Channel Flow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 904,
     "status": "ok",
     "timestamp": 1647241851626,
     "user": {
      "displayName": "muhamad kuroyuki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1bjUJcxjD9YfQtTUthqjbEtihULJ54H7RmBNu=s64",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "GcYF_vFYZCyZ"
   },
   "outputs": [],
   "source": [
    "def generate_param():\n",
    "    params = {}\n",
    "\n",
    "    params[\"data\"] = {}\n",
    "    params[\"data\"][\"lb\"] = np.array([0., 0.])\n",
    "    params[\"data\"][\"ub\"] = np.array([1.0, 1.0])\n",
    "    params[\"data\"][\"n_collo\"] = 25000\n",
    "    n = 401 \n",
    "    params[\"data\"][\"n_left\"] = n #51\n",
    "    params[\"data\"][\"n_right\"] = n #51\n",
    "    params[\"data\"][\"n_initial\"] = n #201\n",
    "    params[\"data\"][\"n_test\"] = 201\n",
    "    params[\"data\"][\"seed\"] = 543212345\n",
    "    loc_num = 6\n",
    "    params[\"data\"][\"loc\"] = np.linspace(0, 1, loc_num) #in %\n",
    "    params[\"data\"][\"meu\"] = [n]*loc_num\n",
    "\n",
    "    params[\"network\"] = {}\n",
    "    params[\"network\"][\"coef_bc\"] = 10000.0\n",
    "    params[\"network\"][\"verboses_newton\"] = 100\n",
    "    \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beNqkcfmZJtv"
   },
   "source": [
    "#### **Poiseuille Flow - VP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUYLHAeiaRmo"
   },
   "source": [
    "##### **Generate Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 951
    },
    "executionInfo": {
     "elapsed": 2784,
     "status": "ok",
     "timestamp": 1647107041518,
     "user": {
      "displayName": "muhamad kuroyuki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1bjUJcxjD9YfQtTUthqjbEtihULJ54H7RmBNu=s64",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "fefxq0D_ZNst",
    "outputId": "ecebe588-3d60-40a7-8fd5-dc11fc9e03c9"
   },
   "outputs": [],
   "source": [
    "# prob = 'Direct'\n",
    "prob = 'Inverse'\n",
    "\n",
    "params = generate_param()\n",
    "params[\"data\"][\"noise\"] = 0.0\n",
    "\n",
    "params[\"network\"][\"layers\"] = [2] + 8*[30] + [1]\n",
    "if prob == \"Inverse\":\n",
    "    params[\"network\"][\"layers_B\"] = [1] + 2*[20] + [1] #3 20\n",
    "    \n",
    "case = CasesChannel(add_noise=True)\n",
    "case.generate_train_data(param=params)\n",
    "case.generate_test_data(param=params)\n",
    "case.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJOUZyXRZgwz"
   },
   "source": [
    "##### **Run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27358,
     "status": "ok",
     "timestamp": 1647107164636,
     "user": {
      "displayName": "muhamad kuroyuki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1bjUJcxjD9YfQtTUthqjbEtihULJ54H7RmBNu=s64",
      "userId": "14682693431505581441"
     },
     "user_tz": -420
    },
    "id": "pdRbx7ICZiD3",
    "outputId": "039c0af4-1c2a-4d5c-d795-6e425b938f3b"
   },
   "outputs": [],
   "source": [
    "# Create Model Instance\n",
    "model = PinnVP(data=case.data, params=params, problem_type=prob)\n",
    "              #  exist_model=True, file_dir='/content/poiseuille-vp.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hObAm2Nlyr4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit using ADAM\n",
    "model.fit_newton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Results\n",
    "results = PostChannel(model=model,\n",
    "                      params=params,\n",
    "                      save_fig=False)\n",
    "\n",
    "results.display_loss()\n",
    "results.display_contour()\n",
    "\n",
    "# Save model\n",
    "# model.save_model('test.pickle')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Heat Conduction - Inverse - type AB aman.ipynb",
   "provenance": [
    {
     "file_id": "1DquI6-opM6DDVTGby5XDaQdDuZQRlcl1",
     "timestamp": 1643096956064
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
